{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/data-science-bowl-2019/sample_submission.csv\n",
      "/kaggle/input/data-science-bowl-2019/specs.csv\n",
      "/kaggle/input/data-science-bowl-2019/train_labels.csv\n",
      "/kaggle/input/data-science-bowl-2019/test.csv\n",
      "/kaggle/input/data-science-bowl-2019/train.csv\n",
      "/kaggle/input/amma-reduce/amma_train.csv\n",
      "/kaggle/input/amma-reduce/amma_test.csv\n",
      "/kaggle/input/amma-reduce-train/amma_reduce_train.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "from catboost import CatBoostRegressor\n",
    "from matplotlib import pyplot\n",
    "import shap\n",
    "\n",
    "from time import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import cohen_kappa_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import gc\n",
    "import json\n",
    "\n",
    "from pandas.io.json import json_normalize\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import json\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import Counter\n",
    "from scipy import stats as sp\n",
    "from scipy import optimize as spoptimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from sklearn import metrics\n",
    "#import scipy as sp\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.stats import boxcox, skew, randint, uniform\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.linear_model import Lasso, ElasticNet, Ridge, LinearRegression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import InputLayer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics, preprocessing\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/kaggle/input/data-science-bowl-2019/train.csv\")\n",
    "test = pd.read_csv(\"/kaggle/input/data-science-bowl-2019/test.csv\")\n",
    "train_labels = pd.read_csv(\"/kaggle/input/data-science-bowl-2019/train_labels.csv\")\n",
    "specs = pd.read_csv(\"/kaggle/input/data-science-bowl-2019/specs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train.installation_id.isin(train_labels.installation_id.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_parser(dataframe, column):\n",
    "    dataframe.reset_index(drop=True, inplace=True)\n",
    "    parsed_set = dataframe[column].apply(json.loads)\n",
    "    parsed_set = json_normalize(parsed_set)\n",
    "    parsed_set.drop(columns=['event_count', 'event_code', 'game_time'], inplace=True)\n",
    "    merged_set = pd.merge(\n",
    "        dataframe,\n",
    "        parsed_set,\n",
    "        how='inner',\n",
    "        left_index= True,\n",
    "        right_index=True\n",
    "    )\n",
    "\n",
    "    del merged_set[column]\n",
    "\n",
    "    return merged_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_title(train, test):\n",
    "\n",
    "    train[\"title_event_code\"] = list(map(lambda x, y : str(x) + '_' + str(y), train[\"title\"], train[\"event_code\"]))\n",
    "    test[\"title_event_code\"] = list(map(lambda x, y : str(x) + '_' + str(y), test[\"title\"], test[\"event_code\"]))\n",
    "    unique_title_event_code = list(set(train[\"title_event_code\"].unique()).union(set(test[\"title_event_code\"].unique())))\n",
    "\n",
    "    unique_titles = list(set(train[\"title\"].unique()).union(set(test[\"title\"].unique())))\n",
    "\n",
    "    unique_event_codes = list(set(train[\"event_code\"].unique()).union(set(test[\"event_code\"].unique())))\n",
    "\n",
    "    unique_worlds = list(set(train['world'].unique()).union(set(test['world'].unique())))\n",
    "\n",
    "    unique_event_ids = list(set(train['event_id'].unique()).union(set(test['event_id'].unique())))\n",
    "\n",
    "    unique_assessments = list(set(train[train['type'] == 'Assessment']['title'].value_counts().index).union(set(test[test['type'] == 'Assessment']['title'].value_counts().index)))\n",
    "\n",
    "    unique_games = list(set(train[train['type'] == 'Game']['title'].value_counts().index).union(set(test[test['type'] == 'Game']['title'].value_counts().index)))\n",
    "\n",
    "    unique_clips = list(set(train[train['type'] == 'Clip']['title'].value_counts().index).union(set(test[test['type'] == 'Clip']['title'].value_counts().index)))\n",
    "\n",
    "    unique_activitys = list(set(train[train['type'] == 'Activity']['title'].value_counts().index).union(set(test[test['type'] == 'Activity']['title'].value_counts().index)))\n",
    "\n",
    "    # convert text into datetime\n",
    "    train[\"timestamp\"] = pd.to_datetime(train[\"timestamp\"])\n",
    "    test[\"timestamp\"]  = pd.to_datetime(test[\"timestamp\"])\n",
    "\n",
    "    unique_data = {\n",
    "        \"unique_title_event_code\" : unique_title_event_code,\n",
    "        \"unique_titles\" : unique_titles,\n",
    "        \"unique_event_codes\" : unique_event_codes,\n",
    "        \"unique_worlds\" : unique_worlds,\n",
    "        \"unique_event_ids\" : unique_event_ids,\n",
    "        \"unique_assessments\" : unique_assessments,\n",
    "        \"unique_games\" : unique_games,\n",
    "        \"unique_clips\" : unique_clips,\n",
    "        \"unique_activitys\" : unique_activitys\n",
    "    }\n",
    "\n",
    "    return train, test, unique_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, unique_data = encode_title(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(user_sample,unique_data ,test=False):\n",
    "\n",
    "    final_features = []\n",
    "\n",
    "    features = {}\n",
    "\n",
    "    Assessments_count = {\"count_\"+ass : 0 for ass in unique_data[\"unique_assessments\"]}\n",
    "    Clips_count = {\"count_\"+clip : 0 for clip in unique_data[\"unique_clips\"]}\n",
    "    Games_count = {\"count_\"+game : 0 for game in unique_data[\"unique_games\"]}\n",
    "    Activitys_count = {\"count_\"+activity:0 for activity in unique_data[\"unique_activitys\"]}\n",
    "    Worlds_count = {\"count_\"+world:0 for world in unique_data[\"unique_worlds\"]}\n",
    "    Title_event_code_count = {etc:0 for etc in unique_data[\"unique_title_event_code\"]}\n",
    "    Event_ids_count = {uei:0 for uei in unique_data[\"unique_event_ids\"]}\n",
    "    Event_code_count = {code: 0 for code in unique_data[\"unique_event_codes\"]}\n",
    "\n",
    "    accuracy_groups = {0:0, 1:0, 2:0, 3:0}\n",
    "    accuracy_groups_game = {'game_0':0, 'game_1':0, 'game_2':0, 'game_3':0}\n",
    "\n",
    "    features[\"accumulated_false\"] = 0\n",
    "    features[\"accumulated_true\"] = 0\n",
    "    features[\"accumulated_false_ass\"] = 0\n",
    "    features[\"accumulated_true_ass\"] = 0\n",
    "\n",
    "    Clip_duration_accumulated = {\"accu_duration_\"+clip : 0 for clip in unique_data[\"unique_clips\"]}\n",
    "    Clip_duration = {\"duration_\"+clip : 0 for clip in unique_data[\"unique_clips\"]}\n",
    "\n",
    "    Games_duration_accumulated = {\"accu_duration_\"+game : 0 for game in unique_data[\"unique_games\"]}\n",
    "    Games_duration = {\"duration_\"+game : 0 for game in unique_data[\"unique_games\"]}\n",
    "\n",
    "    Activitys_duration_accumulated = {\"accu_duration_\"+activity:0 for activity in unique_data[\"unique_activitys\"]}\n",
    "    Activitys_duration = {\"duration_\"+activity:0 for activity in unique_data[\"unique_activitys\"]}\n",
    "\n",
    "    Assessments_duration_accumulated = {\"accu_duration_\"+ass : 0 for ass in unique_data[\"unique_assessments\"]}\n",
    "    Assessments_duration = {\"duration_\"+ass : 0 for ass in unique_data[\"unique_assessments\"]}\n",
    "\n",
    "    features.update(accuracy_groups)\n",
    "    features.update(accuracy_groups_game)\n",
    "\n",
    "    for i, session in user_sample.groupby(\"game_session\", sort=False):\n",
    "        \n",
    "        # i = game_session_id\n",
    "\n",
    "        session_type = session.type.iloc[0]\n",
    "        session_title = session.title.iloc[0]\n",
    "        session_world = session.world.iloc[0]\n",
    "\n",
    "        Worlds_count[\"count_\"+session_world] += 1\n",
    "\n",
    "        if session_type == \"Clip\":\n",
    "            # count\n",
    "            Clips_count[\"count_\"+session_title] += 1\n",
    "\n",
    "            # duration\n",
    "            try:\n",
    "                index = session.index.values[0]\n",
    "                duration = (user_sample.timestamp.loc[index+1] - user_sample.timestamp.loc[index]).seconds\n",
    "                Clip_duration[\"duration_\"+session_title] = duration\n",
    "                Clip_duration_accumulated[\"accu_duration_\"+session_title] += duration\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            features[\"predicted_before_title\"] = session_title\n",
    "\n",
    "        if session_type == \"Activity\":\n",
    "            # count\n",
    "            Activitys_count[\"count_\"+session_title] += 1\n",
    "\n",
    "            # duration\n",
    "            duration = round(session.game_time.iloc[-1] / 1000, 2)\n",
    "            Activitys_duration[\"duration_\"+session_title] = duration\n",
    "            Activitys_duration_accumulated[\"accu_duration_\"+session_title] += duration\n",
    "\n",
    "            features[\"predicted_before_title\"] = session_title\n",
    "\n",
    "\n",
    "        if session_type == \"Game\":\n",
    "            # count\n",
    "            Games_count[\"count_\"+session_title] += 1\n",
    "\n",
    "            # duration\n",
    "            duration = round(session.game_time.iloc[-1] / 1000, 2)\n",
    "            Games_duration[\"duration_\"+session_title] = duration\n",
    "            Games_duration_accumulated[\"accu_duration_\"+session_title] += duration\n",
    "\n",
    "            features[\"predicted_before_title\"] = session_title\n",
    "\n",
    "        if (session_type == \"Assessment\") & (test or len(session) > 1):\n",
    "            \n",
    "            predicted_title = session[\"title\"].iloc[0]\n",
    "            predicted_game_session = session[\"game_session\"].iloc[0]\n",
    "            predicted_timestamp_session = session[\"timestamp\"].iloc[0]\n",
    "\n",
    "            features[\"predicted_title\"] = predicted_title\n",
    "            features[\"installation_id\"] = session[\"installation_id\"].iloc[0]\n",
    "            features[\"game_session\"] = predicted_game_session\n",
    "            features[\"timestamp_session\"] = predicted_timestamp_session\n",
    "\n",
    "            pred_title_df = user_sample[user_sample.title == predicted_title]\n",
    "            pred_title_df = pred_title_df[pred_title_df.timestamp < predicted_timestamp_session]\n",
    "\n",
    "            predicted_assessment = {\"pred_bef_attampt\":0,\n",
    "                            \"pred_bef_true\" : np.nan,\n",
    "                            \"pred_bef_false\" : np.nan,\n",
    "                            \"pred_bef_acc_group\": np.nan,\n",
    "                            \"pred_bef_accuracy\": np.nan,\n",
    "                            \"pred_bef_timespent\" : np.nan,\n",
    "                            \"pred_bef_time_diff\":np.nan\n",
    "                            }\n",
    "            try:\n",
    "                if len(pred_title_df) > 2:\n",
    "                    for i, pred_session in pred_title_df.groupby(\"game_session\", sort=False):\n",
    "                        predicted_assessment[\"pred_bef_attampt\"] += 1\n",
    "                        predicted_assessment[\"pred_bef_timespent\"] = round(pred_session.game_time.iloc[-1] / 1000, 2)\n",
    "                        \n",
    "                        if predicted_title == \"Bird Measurer (Assessment)\":\n",
    "                            predicted_data = pred_session[pred_session.event_code == 4110]\n",
    "                        else:\n",
    "                            predicted_data = pred_session[pred_session.event_code == 4100]\n",
    "\n",
    "                        true_attempts = predicted_data[predicted_data.correct == True]['correct'].count()\n",
    "                        false_attempts = predicted_data[predicted_data.correct == False]['correct'].count()\n",
    "                        accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "                        group = accuracy_groups_def(accuracy)\n",
    "\n",
    "                        predicted_assessment[\"pred_bef_true\"] = true_attempts\n",
    "                        predicted_assessment[\"pred_bef_false\"] = false_attempts\n",
    "                        predicted_assessment[\"pred_bef_accuracy\"] = accuracy\n",
    "                        predicted_assessment[\"pred_bef_acc_group\"] = group\n",
    "\n",
    "                    predicted_assessment[\"pred_bef_time_diff\"] = (predicted_timestamp_session - pred_title_df.timestamp.iloc[-1]).seconds\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            \n",
    "            counter_df = user_sample[user_sample.timestamp < predicted_timestamp_session]\n",
    "            \n",
    "            Title_event_code_count = update_counters(Title_event_code_count, \"title_event_code\", counter_df)\n",
    "            Event_ids_count = update_counters(Event_ids_count, \"event_id\", counter_df)\n",
    "            Event_code_count = update_counters(Event_code_count,\"event_code\", counter_df)\n",
    "\n",
    "            features.update(Title_event_code_count.copy())\n",
    "            features.update(Event_ids_count.copy())\n",
    "            features.update(Event_code_count.copy())\n",
    "\n",
    "            ed = AllEventDataFeatures(features, counter_df)\n",
    "            try:\n",
    "                ed.event_code_2000()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                ed.event_code_2010()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                ed.event_code_2020()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                ed.event_code_2030()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                ed.event_code_2025()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                ed.event_code_2035()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                ed.event_code_2040()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                ed.event_code_2050()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                ed.event_code_2060()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                ed.event_code_2070()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                ed.event_code_2075()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                ed.event_code_2080()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                ed.event_code_2081()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                ed.event_code_2083()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                ed.event_code_3010()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                ed.event_code_3020()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                ed.event_code_3021()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                ed.event_code_3110()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                ed.event_code_3120()\n",
    "                ed.event_code_3121()\n",
    "                ed.event_code_4010()\n",
    "                ed.event_code_4020()\n",
    "                ed.event_code_4021()\n",
    "                ed.event_code_4022()\n",
    "                ed.event_code_4025()\n",
    "                ed.event_code_4030()\n",
    "                ed.event_code_4031()\n",
    "                ed.event_code_4035()\n",
    "                ed.event_code_4040()\n",
    "                ed.event_code_4045()\n",
    "                ed.event_code_4050()\n",
    "                ed.event_code_4070()\n",
    "                ed.event_code_4080()\n",
    "                ed.event_code_4090()\n",
    "                ed.event_code_4095()\n",
    "                ed.event_code_4100()\n",
    "                ed.event_code_4110()\n",
    "                ed.event_code_4220()\n",
    "                ed.event_code_4230()\n",
    "                ed.event_code_4235()\n",
    "                ed.event_code_5000()\n",
    "                ed.event_code_5010()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            edf = ed.Event_features\n",
    "            features_ed = ed.features\n",
    "\n",
    "            features.update(edf.copy())\n",
    "            features.update(features_ed.copy())\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            features.update(predicted_assessment.copy())\n",
    "\n",
    "            features.update(Clips_count.copy())\n",
    "            features.update(Clip_duration.copy())\n",
    "            features.update(Clip_duration_accumulated.copy())\n",
    "            features.update(Games_count.copy())\n",
    "            features.update(Games_duration.copy())\n",
    "            features.update(Games_duration_accumulated.copy())\n",
    "            features.update(Activitys_count.copy())\n",
    "            features.update(Activitys_duration.copy())\n",
    "            features.update(Activitys_duration_accumulated.copy())\n",
    "            features.update(Assessments_count.copy())\n",
    "            features.update(Assessments_duration.copy())\n",
    "            features.update(Assessments_duration_accumulated.copy())\n",
    "\n",
    "\n",
    "            final_features.append(features.copy())\n",
    "\n",
    "            try:\n",
    "                # last Assessment\n",
    "                last_assessment = {\n",
    "                                \"last_bef_true\" : np.nan,\n",
    "                                \"last_bef_false\" : np.nan,\n",
    "                                \"last_bef_acc_group\": np.nan,\n",
    "                                \"last_bef_accuracy\": np.nan,\n",
    "                                \"last_bef_timespent\" : np.nan,\n",
    "                                \"last_bef_title\" : np.nan\n",
    "                                }\n",
    "\n",
    "                last_assessment[\"last_bef_timespent\"] = round(session.game_time.iloc[-1] / 1000, 2)\n",
    "\n",
    "                if predicted_title == \"Bird Measurer (Assessment)\":\n",
    "                    predicted_data = session[session.event_code == 4110]\n",
    "                else:\n",
    "                    predicted_data = session[session.event_code == 4100]\n",
    "                \n",
    "                true_attempts = predicted_data[predicted_data.correct == True]['correct'].count()\n",
    "                false_attempts = predicted_data[predicted_data.correct == False]['correct'].count()\n",
    "                accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "                group = accuracy_groups_def(accuracy)\n",
    "\n",
    "                last_assessment[\"last_bef_true\"] = true_attempts\n",
    "                last_assessment[\"last_bef_false\"] = false_attempts\n",
    "                last_assessment[\"last_bef_accuracy\"] = accuracy\n",
    "                last_assessment[\"last_bef_acc_group\"] = group\n",
    "                last_assessment[\"last_bef_title\"] = predicted_title\n",
    "\n",
    "\n",
    "                features.update(last_assessment.copy())\n",
    "        \n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "\n",
    "            # count\n",
    "            Assessments_count[\"count_\"+session_title] += 1\n",
    "\n",
    "            # duration\n",
    "            duration = round(session.game_time.iloc[-1] / 1000, 2)\n",
    "            Assessments_duration[\"duration_\"+session_title] = duration\n",
    "            Assessments_duration_accumulated[\"accu_duration_\"+session_title] += duration\n",
    "\n",
    "        ed = EventDataFeatures(features, session, user_sample, session_type, session_title)\n",
    "        try:\n",
    "            ed.event_code_2000()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            ed.event_code_2010()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            ed.event_code_2020()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            ed.event_code_2030()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            ed.event_code_2025()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            ed.event_code_2035()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            ed.event_code_2040()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            ed.event_code_2050()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            ed.event_code_2060()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            ed.event_code_2070()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            ed.event_code_2075()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            ed.event_code_2080()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            ed.event_code_2081()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            ed.event_code_2083()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            ed.event_code_3010()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            ed.event_code_3020()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            ed.event_code_3021()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            ed.event_code_3110()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            ed.event_code_3120()\n",
    "            ed.event_code_3121()\n",
    "            ed.event_code_4010()\n",
    "            ed.event_code_4020()\n",
    "            ed.event_code_4021()\n",
    "            ed.event_code_4022()\n",
    "            ed.event_code_4025()\n",
    "            ed.event_code_4030()\n",
    "            ed.event_code_4031()\n",
    "            ed.event_code_4035()\n",
    "            ed.event_code_4040()\n",
    "            ed.event_code_4045()\n",
    "            ed.event_code_4050()\n",
    "            ed.event_code_4070()\n",
    "            ed.event_code_4080()\n",
    "            ed.event_code_4090()\n",
    "            ed.event_code_4095()\n",
    "            ed.event_code_4100()\n",
    "            ed.event_code_4110()\n",
    "            ed.event_code_4220()\n",
    "            ed.event_code_4230()\n",
    "            ed.event_code_4235()\n",
    "            ed.event_code_5000()\n",
    "            ed.event_code_5010()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        edf = ed.Event_features\n",
    "        features_ed = ed.features\n",
    "\n",
    "        features.update(edf.copy())\n",
    "        features.update(features_ed.copy())\n",
    "\n",
    "\n",
    "\n",
    "    if test:\n",
    "        return final_features[-1]\n",
    "    else:\n",
    "        return final_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_groups_def(accuracy):\n",
    "    if accuracy == 0:\n",
    "        return 0\n",
    "    elif accuracy == 1:\n",
    "        return 3\n",
    "    elif accuracy == 0.5:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def update_counters(counter: dict, col:str, counter_df):\n",
    "\n",
    "    num_of_session_count = Counter(counter_df[col])\n",
    "\n",
    "    for k in num_of_session_count.keys():\n",
    "        x = k\n",
    "        counter[x] += num_of_session_count[k]\n",
    "    return counter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class EventDataFeatures(object):\n",
    "    def __init__(self, features, session, user_sample, session_type, session_title):\n",
    "        self.features = features\n",
    "        self.session = session\n",
    "        self.user_sample = user_sample\n",
    "        self.session_type = session_type\n",
    "        self.session_title = session_title\n",
    "        self.Event_features = {}\n",
    "        self.unique_event_codes = self.session.event_code.unique()\n",
    "\n",
    "    def event_code_2000(self):\n",
    "        pass\n",
    "\n",
    "    def event_code_2010(self):\n",
    "        \"\"\"\n",
    "        ['The exit game event is triggered when the game is quit. \n",
    "        This is used to compute things like time spent in game. \n",
    "        Depending on platform this may / may not be possible. \n",
    "        NOTE: “quit” also means navigating away from game.']\n",
    "        \"\"\"\n",
    "        if 2010 in self.unique_event_codes:\n",
    "            session_duration = self.session[self.session.event_code == 2010][\"session_duration\"].values[0]\n",
    "            self.Event_features[\"session_duration_\"+self.session_title] = round(session_duration / 1000, 2)\n",
    "\n",
    "    def event_code_2020(self):\n",
    "        \"\"\"\n",
    "        ['The start round event is triggered at the start of a round when \n",
    "        the player is prompted to weigh and arrange the chests. There is only one round per playthrough.\n",
    "         This event provides information about the game characteristics of the round (i.e. resources, objectives, setup). \n",
    "         It is used in calculating things like time spent in a round (for speed and accuracy), attempts at \n",
    "        solving a round, and the number of rounds the player has visited (exposures).']\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def event_code_2025(self):\n",
    "        \"\"\"\n",
    "        ['The reset dinosaurs event is triggered when the player has placed the last dinosaur, \n",
    "        but not all dinosaurs are in the correct position. \n",
    "        This event provides information about the game characteristics of the round (i.e. resources, objectives, setup). \n",
    "        It is used to indicate a significant change in state during play.']\n",
    "        \n",
    "        This event is used for calculating time spent in a round and \n",
    "        the number of rounds the player has completed (completion).\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def event_code_2030(self):\n",
    "        \"\"\"\n",
    "        ['The beat round event is triggered when the player finishes a round by filling the jar.\n",
    "         This event is used for calculating time spent in a round and\n",
    "          the number of rounds the player has completed (completion).']\n",
    "\n",
    "        \"\"\"\n",
    "        if 2030 in self.unique_event_codes:\n",
    "            rounds = self.session[self.session.event_code == 2030]\n",
    "\n",
    "            round_duration = rounds[\"duration\"].values\n",
    "            self.Event_features[\"round_duration_2030_sum_\"+self.session_title] = round_duration.sum()\n",
    "            self.Event_features[\"round_duration_2030_avg_\"+self.session_title] = round_duration.mean()\n",
    "            self.Event_features[\"round_duration_2030_std_\"+self.session_title] = round_duration.std()\n",
    "            self.Event_features[\"round_duration_2030_max_\"+self.session_title] = round_duration.max()\n",
    "            self.Event_features[\"round_duration_2030_min_\"+self.session_title] = round_duration.min()\n",
    "            self.Event_features[\"number_of_attempts_2030_\"+self.session_title] = round_duration.count()\n",
    "\n",
    "            try:\n",
    "                round_rounds = rounds[\"round\"].values\n",
    "                self.Event_features[\"round_2030_max_\"+self.session_title] = round_rounds.max()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                round_misses = rounds[\"misses\"].values\n",
    "                self.Event_features[\"misses_2030_sum_\"+self.session_title] = round_misses.sum()\n",
    "                self.Event_features[\"misses_2030_avg_\"+self.session_title] = round_misses.mean()\n",
    "                self.Event_features[\"misses_2030_max_\"+self.session_title] = round_misses.max()\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    def event_code_2035(self):\n",
    "        \"\"\"\n",
    "        ['The finish filling tub event is triggered after the player finishes filling up the tub. \n",
    "        It is used to separate a section of gameplay that is different from the estimation section of the game.']\n",
    "        \"\"\"\n",
    "        if 2035 in self.unique_event_codes:\n",
    "            rounds = self.session[self.session.event_code == 2035]\n",
    "\n",
    "            round_duration = rounds[\"duration\"].values\n",
    "            self.Event_features[\"round_duration_2035_sum_\"+self.session_title] = round_duration.sum()\n",
    "            self.Event_features[\"round_duration_2035_avg_\"+self.session_title] = round_duration.mean()\n",
    "    \n",
    "    def event_code_2040(self):\n",
    "        \"\"\"\n",
    "        ['The start level event is triggered when a new level begins \n",
    "        (at the same time as the start round event for the first round in the level). \n",
    "        This event is used for calculating time spent in a level (for speed and accuracy), \n",
    "        and the number of levels the player has completed (completion).']\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def event_code_2050(self):\n",
    "        \"\"\"\n",
    "        ['The beat level event is triggered when a level has been completed and \n",
    "        the player has cleared all rounds in the current layout (occurs at the same time as \n",
    "        the beat round event for the last round in the previous level). This event is used for \n",
    "        calculating time spent in a level (for speed and accuracy), \n",
    "        and the number of levels the player has completed (completion).']\n",
    "        \"\"\"\n",
    "        if 2050 in self.unique_event_codes:\n",
    "            level = self.session[self.session.event_code == 2050]\n",
    "\n",
    "            level_duration = level[\"duration\"].values\n",
    "            self.Event_features[\"level_duration_2050_sum_\"+self.session_title] = level_duration.sum()\n",
    "            self.Event_features[\"level_duration_2050_avg_\"+self.session_title] = level_duration.mean()\n",
    "            self.Event_features[\"level_duration_2050_std_\"+self.session_title] = level_duration.std()\n",
    "            self.Event_features[\"level_duration_2050_max_\"+self.session_title] = level_duration.max()\n",
    "            self.Event_features[\"level_duration_2050_min_\"+self.session_title] = level_duration.min()\n",
    "\n",
    "            try:\n",
    "                level_rounds = level[\"level\"].values\n",
    "                self.Event_features[\"level_2050_max_\"+self.session_title] = level_rounds.max()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                level_misses = level[\"misses\"].values\n",
    "                self.Event_features[\"level_misses_2050_sum_\"+self.session_title] = level_misses.sum()\n",
    "                self.Event_features[\"level_misses_2050_avg_\"+self.session_title] = level_misses.mean()\n",
    "                self.Event_features[\"level_misses_2050_sum_\"+self.session_title] = level_misses.std()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    def event_code_2060(self):\n",
    "        \"\"\"\n",
    "        ['The start tutorial event is triggered at the start of the tutorial. \n",
    "        It is used in calculating time spent in the tutorial.']\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def event_code_2070(self):\n",
    "        \"\"\"\n",
    "        ['The beat round event is triggered when the player finishes the tutorial. \n",
    "        This event is used for calculating time spent in the tutorial.']\n",
    "        \"\"\"\n",
    "        if 2070 in self.unique_event_codes:\n",
    "            tutorial = self.session[self.session.event_code == 2070]\n",
    "\n",
    "            tutorial_duration = tutorial[\"duration\"].values\n",
    "            self.Event_features[\"tutorial_duration_2070_sum_\"+self.session_title] = tutorial_duration.sum()\n",
    "            self.Event_features[\"tutorial_duration_2070_avg_\"+self.session_title] = tutorial_duration.mean()\n",
    "            self.Event_features[\"tutorial_duration_2070_std_\"+self.session_title] = tutorial_duration.std()\n",
    "            self.Event_features[\"tutorial_duration_2070_max_\"+self.session_title] = tutorial_duration.max()\n",
    "            self.Event_features[\"tutorial_duration_2070_min_\"+self.session_title] = tutorial_duration.min()\n",
    "    \n",
    "    def event_code_2075(self):\n",
    "        \"\"\"\n",
    "        ['The beat round event is triggered when the player skips the tutorial by clicking on the skip button.\n",
    "         This event is used for calculating time spent in the tutorial.']\n",
    "        \"\"\"\n",
    "        if 2075 in self.unique_event_codes:\n",
    "\n",
    "            tutorial = self.session[self.session.event_code == 2075]\n",
    "\n",
    "            self.Event_features[\"tutorial_skiping_count_2075_\"+self.session_title] = tutorial[\"duration\"].count()\n",
    "\n",
    "    def event_code_2080(self):\n",
    "        \"\"\"\n",
    "        ['The movie started event triggers when an intro or outro movie starts to play. \n",
    "        It identifies the movie being played. This is used to determine how long players \n",
    "        spend watching the movies (more relevant after the first play \n",
    "        through when the skip option is available).']\n",
    "        \"\"\"\n",
    "        if 2080 in self.unique_event_codes:\n",
    "\n",
    "            movie = self.session[self.session.event_code == 2080]\n",
    "\n",
    "            movie_duration = movie[\"duration\"].values\n",
    "            self.Event_features[\"movie_duration_2080_sum_\"+self.session_title] = movie_duration.sum()\n",
    "            self.Event_features[\"movie_duration_2080_avg_\"+self.session_title] = movie_duration.mean()\n",
    "            self.Event_features[\"movie_duration_2080_std_\"+self.session_title] = movie_duration.std()\n",
    "            self.Event_features[\"movie_duration_2080_max_\"+self.session_title] = movie_duration.max()\n",
    "            self.Event_features[\"movie_duration_2080_min_\"+self.session_title] = movie_duration.min()\n",
    "\n",
    "    def event_code_2081(self):\n",
    "        \"\"\"\n",
    "        ['The movie started event triggers when an intro or outro movie starts to play. \n",
    "        It identifies the movie being played. This is used to determine how long players \n",
    "        spend watching the movies (more relevant after the first play \n",
    "        through when the skip option is available).']\n",
    "        \"\"\"\n",
    "        if 2081 in self.unique_event_codes:\n",
    "\n",
    "            movie = self.session[self.session.event_code == 2081]\n",
    "\n",
    "            self.Event_features[\"movie_skiping_count_2081_\"+self.session_title] = movie[\"duration\"].count()\n",
    "    \n",
    "    def event_code_2083(self):\n",
    "        \"\"\"\n",
    "        ['The movie started event triggers when an intro or outro movie starts to play. \n",
    "        It identifies the movie being played. This is used to determine how long players \n",
    "        spend watching the movies (more relevant after the first play \n",
    "        through when the skip option is available).']\n",
    "        \"\"\"\n",
    "        if 2083 in self.unique_event_codes:\n",
    "\n",
    "            movie = self.session[self.session.event_code == 2083]\n",
    "\n",
    "            movie_duration = movie[\"duration\"].values\n",
    "            self.Event_features[\"movie_duration_2083_sum_\"+self.session_title] = movie_duration.sum()\n",
    "            self.Event_features[\"movie_duration_2083_avg_\"+self.session_title] = movie_duration.mean()\n",
    "    \n",
    "    def event_code_3010(self):\n",
    "        \"\"\"\n",
    "        ['The system-initiated instruction event occurs when the game delivers instructions to the player.\n",
    "         It contains information that describes the content of the instruction. This event differs from events 3020\n",
    "          and 3021 as it captures instructions that are not given in response to player action. \n",
    "          These events are used to determine the effectiveness of the instructions. We can answer questions like,\n",
    "         \"did players who received instruction X do better than those who did not?\"']\n",
    "        \"\"\"\n",
    "        if 3010 in self.unique_event_codes:\n",
    "\n",
    "            instruction = self.session[self.session.event_code == 3010]\n",
    "\n",
    "            instruction_duration = instruction[\"total_duration\"].values\n",
    "            self.Event_features[\"instruction_duration_3010_sum_\"+self.session_title] = instruction_duration.sum()\n",
    "            self.Event_features[\"instruction_duration_3010_avg_\"+self.session_title] = instruction_duration.mean()\n",
    "        \n",
    "            #self.Event_features[\"instruction_media_type_3010_\"+self.session_title] = instruction[\"media_type\"].values_count().index[0]\n",
    "            \n",
    "            self.Event_features[\"instruction_media_type_3010_count_\"+self.session_title] = instruction[\"media_type\"].count()\n",
    "\n",
    "    def event_code_3020(self):\n",
    "        \"\"\"\n",
    "        ['The system-initiated feedback (Incorrect) event occurs when the game starts delivering feedback \n",
    "        to the player in response to an incorrect round attempt (pressing the go button with the incorrect answer). \n",
    "        It contains information that describes the content of the instruction. These events are used to determine \n",
    "        the effectiveness of the feedback. We can answer questions like \n",
    "        \"did players who received feedback X do better than those who did not?\"']\n",
    "        \"\"\"\n",
    "        if 3020 in self.unique_event_codes:\n",
    "\n",
    "            Incorrect = self.session[self.session.event_code == 3020]\n",
    "\n",
    "            Incorrect_duration = Incorrect[\"total_duration\"].values\n",
    "            self.Event_features[\"Incorrect_duration_3020_sum_\"+self.session_title] = Incorrect_duration.sum()\n",
    "            self.Event_features[\"Incorrect_duration_3020_avg_\"+self.session_title] = Incorrect_duration.mean()\n",
    "            #self.Event_features[\"Incorrect_duration_3020_std_\"+self.session_title] = Incorrect_duration.std()\n",
    "            #self.Event_features[\"Incorrect_duration_3020_max_\"+self.session_title] = Incorrect_duration.max()\n",
    "            #self.Event_features[\"Incorrect_duration_3020_min_\"+self.session_title] = Incorrect_duration.min()\n",
    "        \n",
    "            #self.Event_features[\"Incorrect_media_type_3020_\"+self.session_title] = Incorrect[\"media_type\"].values[0]\n",
    "            \n",
    "            self.Event_features[\"Incorrect_media_type_3020_count_\"+self.session_title] = Incorrect[\"media_type\"].count()\n",
    "    \n",
    "\n",
    "    def event_code_3021(self):\n",
    "        \"\"\"\n",
    "        ['The system-initiated feedback (Correct) event occurs when the game \n",
    "        starts delivering feedback to the player in response to a correct round attempt \n",
    "        (pressing the go button with the correct answer). It contains information that describes the\n",
    "         content of the instruction, and will likely occur in conjunction with a beat round event. \n",
    "         These events are used to determine the effectiveness of the feedback. We can answer questions like, \n",
    "        \"did players who received feedback X do better than those who did not?\"']\n",
    "        \"\"\"\n",
    "        if 3021 in self.unique_event_codes:\n",
    "\n",
    "            Correct = self.session[self.session.event_code == 3021]\n",
    "\n",
    "            Correct_duration = Correct[\"total_duration\"].values\n",
    "            self.Event_features[\"Correct_duration_3021_sum_\"+self.session_title] = Correct_duration.sum()\n",
    "            self.Event_features[\"Correct_duration_3021_avg_\"+self.session_title] = Correct_duration.mean()\n",
    "            #self.Event_features[\"Correct_duration_3021_std_\"+self.session_title] = Correct_duration.std()\n",
    "            #self.Event_features[\"Correct_duration_3021_max_\"+self.session_title] = Correct_duration.max()\n",
    "            #self.Event_features[\"Correct_duration_3021_min_\"+self.session_title] = Correct_duration.min()\n",
    "        \n",
    "            #self.Event_features[\"Correct_media_type_3021_\"+self.session_title] = Correct[\"media_type\"].values[0]\n",
    "            \n",
    "            self.Event_features[\"Correct_media_type_3021_count_\"+self.session_title] = Correct[\"media_type\"].count()\n",
    "\n",
    "    def event_code_3110(self):\n",
    "        \"\"\"\n",
    "        ['The end of system-initiated instruction event occurs when the game finishes \n",
    "        delivering instructions to the player. It contains information that describes the\n",
    "         content of the instruction including duration. These events are used to determine the \n",
    "         effectiveness of the instructions and the amount of time they consume. We can answer questions like, \n",
    "        \"how much time elapsed while the game was presenting instruction?\"']\n",
    "        \"\"\"\n",
    "        if 3110 in self.unique_event_codes:\n",
    "\n",
    "            Instuction = self.session[self.session.event_code == 3110]\n",
    "\n",
    "            Instuction_duration = Instuction[\"duration\"].values\n",
    "            self.Event_features[\"Instuction_duration_3110_sum_\"+self.session_title] = Instuction_duration.sum()\n",
    "            self.Event_features[\"Instuction_duration_3110_avg_\"+self.session_title] = Instuction_duration.mean()\n",
    "            #self.Event_features[\"Instuction_duration_3110_std_\"+self.session_title] = Instuction_duration.std()\n",
    "            #self.Event_features[\"Instuction_duration_3110_max_\"+self.session_title] = Instuction_duration.max()\n",
    "            #self.Event_features[\"Instuction_duration_3110_min_\"+self.session_title] = Instuction_duration.min()\n",
    "        \n",
    "            #self.Event_features[\"Instuction_media_type_3110_\"+self.session_title] = Instuction[\"media_type\"].values[0]\n",
    "            \n",
    "            self.Event_features[\"Instuction_media_type_3110_count_\"+self.session_title] = Instuction[\"media_type\"].count()\n",
    "\n",
    "    def event_code_3120(self):\n",
    "        \"\"\"\n",
    "        ['The end of system-initiated feedback (Incorrect) event \n",
    "        occurs when the game finishes delivering feedback to the player in response\n",
    "         to an incorrect round attempt (pressing the go button with the incorrect answer). \n",
    "         It contains information that describes the content of the instruction. \n",
    "         These events are used to determine the effectiveness of the feedback. We can answer questions like,\n",
    "         “how much time elapsed while the game was presenting feedback?”']\n",
    "        \"\"\"\n",
    "        if 3120 in self.unique_event_codes:\n",
    "\n",
    "            IncorrectInstruction = self.session[self.session.event_code == 3120]\n",
    "\n",
    "            IncorrectInstruction_duration = IncorrectInstruction[\"duration\"].values\n",
    "            self.Event_features[\"IncorrectInstruction_duration_3120_sum_\"+self.session_title] = IncorrectInstruction_duration.sum()\n",
    "            self.Event_features[\"IncorrectInstruction_duration_3120_avg_\"+self.session_title] = IncorrectInstruction_duration.mean()\n",
    "            #self.Event_features[\"IncorrectInstruction_duration_3120_std_\"+self.session_title] = IncorrectInstruction_duration.std()\n",
    "            #self.Event_features[\"IncorrectInstruction_duration_3120_max_\"+self.session_title] = IncorrectInstruction_duration.max()\n",
    "            #self.Event_features[\"IncorrectInstruction_duration_3120_min_\"+self.session_title] = IncorrectInstruction_duration.min()\n",
    "        \n",
    "            #self.Event_features[\"IncorrectInstruction_media_type_3120_\"+self.session_title] = IncorrectInstruction[\"media_type\"].values[0]\n",
    "            \n",
    "            self.Event_features[\"IncorrectInstruction_media_type_3120_count_\"+self.session_title] = IncorrectInstruction[\"media_type\"].count()\n",
    "\n",
    "    def event_code_3121(self):\n",
    "        \"\"\"\n",
    "        ['The end of system-initiated feedback (Correct) event \n",
    "        occurs when the game finishes delivering feedback to the player in response\n",
    "         to an incorrect round attempt (pressing the go button with the incorrect answer). \n",
    "         It contains information that describes the content of the instruction. \n",
    "         These events are used to determine the effectiveness of the feedback. We can answer questions like,\n",
    "         “how much time elapsed while the game was presenting feedback?”']\n",
    "        \"\"\"\n",
    "        if 3121 in self.unique_event_codes:\n",
    "\n",
    "            CorrectInstruction = self.session[self.session.event_code == 3121]\n",
    "\n",
    "            CorrectInstruction_duration = CorrectInstruction[\"duration\"].values\n",
    "            self.Event_features[\"CorrectInstruction_duration_3121_sum_\"+self.session_title] = CorrectInstruction_duration.sum()\n",
    "            self.Event_features[\"CorrectInstruction_duration_3121_avg_\"+self.session_title] = CorrectInstruction_duration.mean()\n",
    "            #self.Event_features[\"CorrectInstruction_duration_3121_std_\"+self.session_title] = CorrectInstruction_duration.std()\n",
    "            #self.Event_features[\"CorrectInstruction_duration_3121_max_\"+self.session_title] = CorrectInstruction_duration.max()\n",
    "            #self.Event_features[\"CorrectInstruction_duration_3121_min_\"+self.session_title] = CorrectInstruction_duration.min()\n",
    "        \n",
    "            #self.Event_features[\"CorrectInstruction_media_type_3121_\"+self.session_title] = CorrectInstruction[\"media_type\"].values[0]\n",
    "            \n",
    "            self.Event_features[\"CorrectInstruction_media_type_3121_count_\"+self.session_title] = CorrectInstruction[\"media_type\"].count()\n",
    "\n",
    "\n",
    "    def event_code_4010(self):\n",
    "        \"\"\"\n",
    "\n",
    "        ['This event occurs when the player clicks to start \n",
    "        the game from the starting screen.']\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        if 4010 in self.unique_event_codes:\n",
    "            \n",
    "\n",
    "            click_start = self.session[self.session.event_code == 4010]\n",
    "            index = click_start.index.values[0]\n",
    "            duration = (self.user_sample.timestamp.loc[index] - self.user_sample.timestamp.loc[index-1]).seconds\n",
    "\n",
    "            self.Event_features[\"click_start_duration_4010_\"+self.session_title] = duration\n",
    "    \n",
    "    def event_code_4020(self):\n",
    "        \"\"\"\n",
    "        ['This event occurs when the player \n",
    "        clicks a group of objects. It contains information \n",
    "        about the group clicked, the state of the game, and the\n",
    "         correctness of the action. This event is \n",
    "         to diagnose player strategies and understanding.']\n",
    "\n",
    "         It contains information about the state of the game and the correctness of the action. This event is used \n",
    "         to diagnose player strategies and understanding.\n",
    "        \"\"\"\n",
    "        \n",
    "        if 4020 in self.unique_event_codes:\n",
    "\n",
    "            event_data = self.session[self.session.event_code == 4020]\n",
    "\n",
    "            if self.session_title == \"Bottle Filler (Activity)\":\n",
    "                true_attempts = event_data[event_data.jar_filled == True]['jar_filled'].count()\n",
    "                false_attempts = event_data[event_data.jar_filled == False]['jar_filled'].count()\n",
    "                accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "\n",
    "                self.Event_features[\"True_attempts_4020_\"+self.session_title] = true_attempts\n",
    "                self.Event_features[\"False_attempts_4020_\"+self.session_title] = false_attempts\n",
    "                self.Event_features[\"Accuracy_attempts_4020_\"+self.session_title] = accuracy\n",
    "                \n",
    "                group = accuracy_groups_def(accuracy)\n",
    "\n",
    "                self.features['game_'+str(group)] += 1\n",
    "                self.features[\"accumulated_false\"] += false_attempts\n",
    "                self.features[\"accumulated_true\"] += true_attempts\n",
    "\n",
    "            elif self.session_title == 'Sandcastle Builder (Activity)':\n",
    "                sandcastle_duration = event_data[\"duration\"].values\n",
    "                self.Event_features[\"sandcastle_duration_4020_sum_\"+self.session_title] = sandcastle_duration.sum()\n",
    "                self.Event_features[\"sandcastle_duration_4020_avg_\"+self.session_title] = sandcastle_duration.mean()\n",
    "                #self.Event_features[\"sandcastle_duration_4020_std_\"+self.session_title] = sandcastle_duration.std()\n",
    "                #self.Event_features[\"sandcastle_duration_4020_max_\"+self.session_title] = sandcastle_duration.max()\n",
    "                #self.Event_features[\"sandcastle_duration_4020_min_\"+self.session_title] = sandcastle_duration.min()\n",
    "\n",
    "            elif self.session_title == \"Cart Balancer (Assessment)\":\n",
    "                try:\n",
    "                    true_attempts = event_data[event_data.size == 'left']['size'].count()\n",
    "                    false_attempts = event_data[event_data.size == 'right']['size'].count()\n",
    "                    accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "\n",
    "                    self.Event_features[\"Left_attempts_4020_\"+self.session_title] = true_attempts\n",
    "                    self.Event_features[\"Right_attempts_4020_\"+self.session_title] = false_attempts\n",
    "                    self.Event_features[\"Accuracy_attempts_4020_\"+self.session_title] = accuracy\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    group = accuracy_groups_def(accuracy)\n",
    "                    self.features['game_'+str(group)] += 1\n",
    "\n",
    "                    self.features[\"accumulated_false\"] += false_attempts\n",
    "                    self.features[\"accumulated_true\"] += true_attempts\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            elif self.session_title == \"Fireworks (Activity)\":\n",
    "                true_attempts = event_data[event_data.launched == True]['launched'].count()\n",
    "                false_attempts = event_data[event_data.launched == False]['launched'].count()\n",
    "                accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "\n",
    "                self.Event_features[\"True_attempts_4020_\"+self.session_title] = true_attempts\n",
    "                self.Event_features[\"False_attempts_4020_\"+self.session_title] = false_attempts\n",
    "                self.Event_features[\"Accuracy_attempts_4020_\"+self.session_title] = accuracy\n",
    "                \n",
    "                group = accuracy_groups_def(accuracy)\n",
    "                self.features['game_'+str(group)] += 1\n",
    "                \n",
    "                \n",
    "                self.features[\"accumulated_false\"] += false_attempts\n",
    "                self.features[\"accumulated_true\"] += true_attempts\n",
    "\n",
    "                rocket_duration = event_data[\"duration\"].values\n",
    "                self.Event_features[\"rocket_duration_4020_sum_\"+self.session_title] = rocket_duration.sum()\n",
    "                self.Event_features[\"rocket_duration_4020_avg_\"+self.session_title] = rocket_duration.mean()\n",
    "                self.Event_features[\"rocket_duration_4020_std_\"+self.session_title] = rocket_duration.std()\n",
    "                self.Event_features[\"rocket_duration_4020_max_\"+self.session_title] = rocket_duration.max()\n",
    "                self.Event_features[\"rocket_duration_4020_min_\"+self.session_title] = rocket_duration.min()\n",
    "\n",
    "                rocket_height = event_data[\"height\"].values\n",
    "                self.Event_features[\"rocket_height_4020_sum_\"+self.session_title] = rocket_height.sum()\n",
    "                self.Event_features[\"rocket_height_4020_avg_\"+self.session_title] = rocket_height.mean()\n",
    "                self.Event_features[\"rocket_height_4020_std_\"+self.session_title] = rocket_height.std()\n",
    "                self.Event_features[\"rocket_height_4020_max_\"+self.session_title] = rocket_height.max()\n",
    "                self.Event_features[\"rocket_height_4020_min_\"+self.session_title] = rocket_height.min()\n",
    "\n",
    "            elif self.session_title == \"Watering Hole (Activity)\":\n",
    "                \n",
    "                water_level = event_data[\"water_level\"].values\n",
    "                self.Event_features[\"water_level_4020_sum_\"+self.session_title] = water_level.sum()\n",
    "                self.Event_features[\"water_level_4020_avg_\"+self.session_title] = water_level.mean()\n",
    "                self.Event_features[\"water_level_4020_std_\"+self.session_title] = water_level.std()\n",
    "                self.Event_features[\"water_level_4020_max_\"+self.session_title] = water_level.max()\n",
    "                self.Event_features[\"water_level_4020_min_\"+self.session_title] = water_level.min()\n",
    "\n",
    "            elif self.session_title == \"Chicken Balancer (Activity)\":\n",
    "                \n",
    "                true_attempts = event_data[event_data[\"layout.right.pig\"] == True]['layout.right.pig'].count()\n",
    "                false_attempts = event_data[event_data[\"layout.right.pig\"] == False]['layout.right.pig'].count()\n",
    "                accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "\n",
    "                self.Event_features[\"True_attempts_4020_\"+self.session_title] = true_attempts\n",
    "                self.Event_features[\"False_attempts_4020_\"+self.session_title] = false_attempts\n",
    "                self.Event_features[\"Accuracy_attempts_4020_\"+self.session_title] = accuracy\n",
    "\n",
    "            elif self.session_title == 'Flower Waterer (Activity)':\n",
    "                \n",
    "                flower_duration = event_data[\"duration\"].values\n",
    "                self.Event_features[\"flower_duration_4020_sum_\"+self.session_title] = flower_duration.sum()\n",
    "                self.Event_features[\"flower_duration_4020_avg_\"+self.session_title] = flower_duration.mean()\n",
    "                #self.Event_features[\"flower_duration_4020_std_\"+self.session_title] = flower_duration.std()\n",
    "                #self.Event_features[\"flower_duration_4020_max_\"+self.session_title] = flower_duration.max()\n",
    "                #self.Event_features[\"flower_duration_4020_min_\"+self.session_title] = flower_duration.min()\n",
    "            \n",
    "            elif self.session_title == \"Egg Dropper (Activity)\":\n",
    "                \n",
    "                true_attempts = event_data[event_data[\"gate.side\"] == 'left']['gate.side'].count()\n",
    "                false_attempts = event_data[event_data[\"gate.side\"] == 'right']['gate.side'].count()\n",
    "                accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "\n",
    "                self.Event_features[\"Left_attempts_4020_\"+self.session_title] = true_attempts\n",
    "                self.Event_features[\"Right_attempts_4020_\"+self.session_title] = false_attempts\n",
    "                self.Event_features[\"Accuracy_attempts_4020_\"+self.session_title] = accuracy\n",
    "\n",
    "            else:\n",
    "                true_attempts = event_data[event_data.correct == True]['correct'].count()\n",
    "                false_attempts = event_data[event_data.correct == False]['correct'].count()\n",
    "                accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "\n",
    "                self.Event_features[\"True_attempts_4020_\"+self.session_title] = true_attempts\n",
    "                self.Event_features[\"False_attempts_4020_\"+self.session_title] = false_attempts\n",
    "                self.Event_features[\"Accuracy_attempts_4020_\"+self.session_title] = accuracy\n",
    "                \n",
    "                \n",
    "                \n",
    "                group = accuracy_groups_def(accuracy)\n",
    "                self.features['game_'+str(group)] += 1\n",
    "                \n",
    "                self.features[\"accumulated_false\"] += false_attempts\n",
    "                self.features[\"accumulated_true\"] += true_attempts\n",
    "\n",
    "    def event_code_4021(self):\n",
    "\n",
    "        if 4021 in self.unique_event_codes:\n",
    "\n",
    "            event_data = self.session[self.session.event_code == 4021]\n",
    "\n",
    "            if self.session_title == \"Sandcastle Builder (Activity)\":\n",
    "                amount_sand = event_data[\"sand\"].values\n",
    "                self.Event_features[\"amount_sand_4020_sum_\"+self.session_title] = amount_sand.sum()\n",
    "                self.Event_features[\"amount_sand_4020_avg_\"+self.session_title] = amount_sand.mean()\n",
    "                #self.Event_features[\"amount_sand_4020_std_\"+self.session_title] = amount_sand.std()\n",
    "                self.Event_features[\"amount_sand_4020_max_\"+self.session_title] = amount_sand.max()\n",
    "                #self.Event_features[\"amount_sand_4020_min_\"+self.session_title] = amount_sand.min()\n",
    "            \n",
    "            elif self.session_title == 'Watering Hole (Activity)':\n",
    "                cloud_size = event_data[\"cloud_size\"].values\n",
    "                self.Event_features[\"cloud_size_4020_sum_\"+self.session_title] = cloud_size.sum()\n",
    "                self.Event_features[\"cloud_size_4020_avg_\"+self.session_title] = cloud_size.mean()\n",
    "                #self.Event_features[\"cloud_size_4020_std_\"+self.session_title] = cloud_size.std()\n",
    "                self.Event_features[\"cloud_size_4020_max_\"+self.session_title] = cloud_size.max()\n",
    "                #self.Event_features[\"cloud_size_4020_min_\"+self.session_title] = cloud_size.min()\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "    def event_code_4022(self):\n",
    "        pass\n",
    "\n",
    "    def event_code_4025(self):\n",
    "        if 4025 in self.unique_event_codes:\n",
    "\n",
    "            event_data = self.session[self.session.event_code == 4025]\n",
    "\n",
    "            if self.session_title == \"Cauldron Filler (Assessment)\":\n",
    "                true_attempts = event_data[event_data.correct == True]['correct'].count()\n",
    "                false_attempts = event_data[event_data.correct == False]['correct'].count()\n",
    "                accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "\n",
    "                self.Event_features[\"True_attempts_4025_\"+self.session_title] = true_attempts\n",
    "                self.Event_features[\"False_attempts_4025_\"+self.session_title] = false_attempts\n",
    "                self.Event_features[\"Accuracy_attempts_4025_\"+self.session_title] = accuracy\n",
    "                \n",
    "                group = accuracy_groups_def(accuracy)\n",
    "                self.features['game_'+str(group)] += 1\n",
    "                \n",
    "                self.features[\"accumulated_false\"] += false_attempts\n",
    "                self.features[\"accumulated_true\"] += true_attempts\n",
    "            \n",
    "            elif self.session_title == \"Bug Measurer (Activity)\":\n",
    "\n",
    "                self.Event_features[\"Bug_length_max_4025_\"+self.session_title] = event_data[\"buglength\"].max()\n",
    "                self.Event_features[\"Number_of_Bugs_4025_\"+self.session_title] = event_data[\"buglength\"].count()\n",
    "            \n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    def event_code_4030(self):\n",
    "        pass\n",
    "\n",
    "    def event_code_4031(self):\n",
    "        pass\n",
    "\n",
    "    def event_code_4035(self):\n",
    "\n",
    "        if 4035 in self.unique_event_codes:\n",
    "\n",
    "            event_data = self.session[self.session.event_code == 4035]\n",
    "\n",
    "            self.Event_features[\"wrong_place_count_4035_\"+self.session_title] = len(event_data)\n",
    "\n",
    "            if self.session_title == \"All Star Sorting\":\n",
    "\n",
    "                wrong_place = event_data[\"duration\"].values\n",
    "                self.Event_features[\"wrong_place_duration_4035_sum_\"+self.session_title] = wrong_place.sum()\n",
    "                self.Event_features[\"wrong_place_duration_4035_avg_\"+self.session_title] = wrong_place.mean()\n",
    "                #self.Event_features[\"wrong_place_duration_4035_std_\"+self.session_title] = wrong_place.std()\n",
    "                #self.Event_features[\"wrong_place_duration_4035_max_\"+self.session_title] = wrong_place.max()\n",
    "                #self.Event_features[\"wrong_place_duration_4035_min_\"+self.session_title] = wrong_place.min()\n",
    "\n",
    "            elif self.session_title == \"Bug Measurer (Activity)\":\n",
    "\n",
    "                wrong_place = event_data[\"duration\"].values\n",
    "                self.Event_features[\"wrong_place_duration_4035_sum_\"+self.session_title] = wrong_place.sum()\n",
    "                self.Event_features[\"wrong_place_duration_4035_avg_\"+self.session_title] = wrong_place.mean()\n",
    "                #self.Event_features[\"wrong_place_duration_4035_std_\"+self.session_title] = wrong_place.std()\n",
    "                #self.Event_features[\"wrong_place_duration_4035_max_\"+self.session_title] = wrong_place.max()\n",
    "                #self.Event_features[\"wrong_place_duration_4035_min_\"+self.session_title] = wrong_place.min()\n",
    "\n",
    "            elif self.session_title == \"Pan Balance\":\n",
    "                pass\n",
    "\n",
    "            elif self.session_title == \"Chicken Balancer (Activity)\":\n",
    "                wrong_place = event_data[\"duration\"].values\n",
    "                self.Event_features[\"wrong_place_duration_4035_sum_\"+self.session_title] = wrong_place.sum()\n",
    "                self.Event_features[\"wrong_place_duration_4035_avg_\"+self.session_title] = wrong_place.mean()\n",
    "                #self.Event_features[\"wrong_place_duration_4035_std_\"+self.session_title] = wrong_place.std()\n",
    "                #self.Event_features[\"wrong_place_duration_4035_max_\"+self.session_title] = wrong_place.max()\n",
    "                #self.Event_features[\"wrong_place_duration_4035_min_\"+self.session_title] = wrong_place.min()\n",
    "\n",
    "            elif self.session_title == \"Chest Sorter (Assessment)\":\n",
    "\n",
    "                wrong_place = event_data[\"duration\"].values\n",
    "                self.Event_features[\"wrong_place_duration_4035_sum_\"+self.session_title] = wrong_place.sum()\n",
    "                self.Event_features[\"wrong_place_duration_4035_avg_\"+self.session_title] = wrong_place.mean()\n",
    "                #self.Event_features[\"wrong_place_duration_4035_std_\"+self.session_title] = wrong_place.std()\n",
    "                #self.Event_features[\"wrong_place_duration_4035_max_\"+self.session_title] = wrong_place.max()\n",
    "                #self.Event_features[\"wrong_place_duration_4035_min_\"+self.session_title] = wrong_place.min()\n",
    "\n",
    "            else:\n",
    "\n",
    "                try:\n",
    "                    wrong_place = event_data[\"duration\"].values\n",
    "                    self.Event_features[\"wrong_place_duration_4035_sum_\"+self.session_title] = wrong_place.sum()\n",
    "                    self.Event_features[\"wrong_place_duration_4035_avg_\"+self.session_title] = wrong_place.mean()\n",
    "                    #self.Event_features[\"wrong_place_duration_4035_std_\"+self.session_title] = wrong_place.std()\n",
    "                    #self.Event_features[\"wrong_place_duration_4035_max_\"+self.session_title] = wrong_place.max()\n",
    "                    #self.Event_features[\"wrong_place_duration_4035_min_\"+self.session_title] = wrong_place.min()\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    def event_code_4040(self):\n",
    "        pass\n",
    "\n",
    "    def event_code_4045(self):\n",
    "        pass\n",
    "\n",
    "    def event_code_4050(self):\n",
    "        pass\n",
    "\n",
    "    def event_code_4070(self):\n",
    "        \"\"\"\n",
    "        \n",
    "        ['This event occurs when the player clicks on\n",
    "            something that isn’t covered elsewhere. \n",
    "            It can be useful in determining if there are\n",
    "            attractive distractions (things the player think\n",
    "            should do something, but don’t) in the game, or\n",
    "            diagnosing players \n",
    "            who are having mechanical difficulties (near misses).']\n",
    "        \"\"\"\n",
    "        if 4070 in self.unique_event_codes:\n",
    "\n",
    "            event_data = self.session[self.session.event_code == 4070]\n",
    "\n",
    "            self.Event_features[\"something_not_covered_count_4070_\"+self.session_title] = len(event_data)\n",
    "\n",
    "    def event_code_4080(self):\n",
    "\n",
    "        if 4080 in self.unique_event_codes:\n",
    "\n",
    "            event_data = self.session[self.session.event_code == 4080]\n",
    "\n",
    "            self.Event_features[\"mouse_over_count_4080_\"+self.session_title] = len(event_data)\n",
    "\n",
    "            try:\n",
    "\n",
    "                dwell_time = event_data[\"dwell_time\"].values\n",
    "                self.Event_features[\"dwell_time_duration_4080_sum_\"+self.session_title] = dwell_time.sum()\n",
    "                self.Event_features[\"dwell_time_duration_4080_avg_\"+self.session_title] = dwell_time.mean()\n",
    "                self.Event_features[\"dwell_time_duration_4080_std_\"+self.session_title] = dwell_time.std()\n",
    "                self.Event_features[\"dwell_time_duration_4080_max_\"+self.session_title] = dwell_time.max()\n",
    "                self.Event_features[\"dwell_time_duration_4080_min_\"+self.session_title] = dwell_time.min()\n",
    "            \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    def event_code_4090(self):\n",
    "\n",
    "        if 4090 in self.unique_event_codes:\n",
    "\n",
    "            event_data = self.session[self.session.event_code == 4090]\n",
    "\n",
    "            self.Event_features[\"Player_help_count_4090_\"+self.session_title] = len(event_data)\n",
    "\n",
    "    def event_code_4095(self):\n",
    "\n",
    "        if 4095 in self.unique_event_codes:\n",
    "\n",
    "            event_data = self.session[self.session.event_code == 4095]\n",
    "\n",
    "            self.Event_features[\"Plage_again_4095_\"+self.session_title] = len(event_data)\n",
    "        \n",
    "    def event_code_4100(self):\n",
    "        \n",
    "        if 4100 in self.unique_event_codes:\n",
    "\n",
    "            event_data = self.session[self.session.event_code == 4100]\n",
    "\n",
    "            true_attempts = event_data[event_data.correct == True]['correct'].count()\n",
    "            false_attempts = event_data[event_data.correct == False]['correct'].count()\n",
    "            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "\n",
    "            self.Event_features[\"True_attempts_4100_\"+self.session_title] = true_attempts\n",
    "            self.Event_features[\"False_attempts_4100_\"+self.session_title] = false_attempts\n",
    "            self.Event_features[\"Accuracy_attempts_4100_\"+self.session_title] = accuracy\n",
    "            \n",
    "            group = accuracy_groups_def(accuracy)\n",
    "            self.features[group] += 1\n",
    "            \n",
    "            self.features[\"accumulated_false_ass\"] += false_attempts\n",
    "            self.features[\"accumulated_true_ass\"] += true_attempts\n",
    "\n",
    "    def event_code_4110(self):\n",
    "        \n",
    "\n",
    "        if 4110 in self.unique_event_codes:\n",
    "\n",
    "            event_data = self.session[self.session.event_code == 4110]\n",
    "\n",
    "            true_attempts = event_data[event_data.correct == True]['correct'].count()\n",
    "            false_attempts = event_data[event_data.correct == False]['correct'].count()\n",
    "            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "\n",
    "            self.Event_features[\"True_attempts_4110_\"+self.session_title] = true_attempts\n",
    "            self.Event_features[\"False_attempts_4110_\"+self.session_title] = false_attempts\n",
    "            self.Event_features[\"Accuracy_attempts_4110_\"+self.session_title] = accuracy\n",
    "            \n",
    "            group = accuracy_groups_def(accuracy)\n",
    "            self.features[group] += 1\n",
    "            \n",
    "            self.features[\"accumulated_false_ass\"] += false_attempts\n",
    "            self.features[\"accumulated_true_ass\"] += true_attempts\n",
    "            \n",
    "\n",
    "    def event_code_4220(self):\n",
    "        pass\n",
    "\n",
    "    def event_code_4230(self):\n",
    "        pass\n",
    "\n",
    "    def event_code_4235(self):\n",
    "        pass\n",
    "\n",
    "    def event_code_5000(self):\n",
    "        pass\n",
    "\n",
    "    def event_code_5010(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "def FeaturesGeneration(x, feature_name):\n",
    "    feature_dict = dict()\n",
    "\n",
    "    feature_dict['mean'+feature_name] = np.mean(x)\n",
    "    feature_dict['max'+feature_name] = np.max(x)\n",
    "    feature_dict['min'+feature_name] = np.min(x)\n",
    "    feature_dict['std'+feature_name] = np.std(x)\n",
    "    feature_dict['var'+feature_name] = np.var(x)\n",
    "    feature_dict['ptp'+feature_name] = np.ptp(x)\n",
    "    feature_dict['percentile_10'+feature_name] = np.percentile(x, 10)\n",
    "    feature_dict['percentile_20'+feature_name] = np.percentile(x, 20)\n",
    "    feature_dict['percentile_30'+feature_name] = np.percentile(x, 30)\n",
    "    feature_dict['percentile_40'+feature_name] = np.percentile(x, 40)\n",
    "    feature_dict['percentile_50'+feature_name] = np.percentile(x, 50)\n",
    "    feature_dict['percentile_60'+feature_name] = np.percentile(x, 60)\n",
    "    feature_dict['percentile_70'+feature_name] = np.percentile(x, 70)\n",
    "    feature_dict['percentile_80'+feature_name] = np.percentile(x, 80)\n",
    "    feature_dict['percentile_90'+feature_name] = np.percentile(x, 90)\n",
    "\n",
    "    # scipy\n",
    "    feature_dict['skew'+feature_name] = sp.stats.skew(x)\n",
    "    feature_dict['kurtosis'+feature_name] = sp.stats.kurtosis(x)\n",
    "    feature_dict['kstat_1'+feature_name] = sp.kstat(x, 1)\n",
    "    feature_dict['kstat_2'+feature_name] = sp.kstat(x, 2)\n",
    "    feature_dict['kstat_3'+feature_name] = sp.kstat(x, 3)\n",
    "    feature_dict['kstat_4'+feature_name] = sp.kstat(x, 4)\n",
    "    feature_dict['moment_1'+feature_name] = sp.stats.moment(x, 1)\n",
    "    feature_dict['moment_2'+feature_name] = sp.stats.moment(x, 2)\n",
    "    feature_dict['moment_3'+feature_name] = sp.stats.moment(x, 3)\n",
    "    feature_dict['moment_4'+feature_name] = sp.stats.moment(x, 4)\n",
    "\n",
    "    return feature_dict\n",
    "\n",
    "\n",
    "class AllEventDataFeatures(object):\n",
    "    def __init__(self, features, user_sample):\n",
    "        self.features = features\n",
    "        self.user_sample = user_sample\n",
    "        self.Event_features = {}\n",
    "        self.unique_event_codes = self.user_sample.event_code.unique()\n",
    "\n",
    "    def event_code_2000(self):\n",
    "        pass\n",
    "\n",
    "    def event_code_2010(self):\n",
    "        \"\"\"\n",
    "        ['The exit game event is triggered when the game is quit. \n",
    "        This is used to compute things like time spent in game. \n",
    "        Depending on platform this may / may not be possible. \n",
    "        NOTE: “quit” also means navigating away from game.']\n",
    "        \"\"\"\n",
    "        if 2010 in self.unique_event_codes:\n",
    "            session_duration = self.user_sample[self.user_sample.event_code == 2010][\"session_duration\"].values\n",
    "            features_2010 = FeaturesGeneration(session_duration, \"_2010\")\n",
    "            self.Event_features.update(features_2010.copy())\n",
    "\n",
    "    def event_code_2020(self):\n",
    "        \"\"\"\n",
    "        ['The start round event is triggered at the start of a round when \n",
    "        the player is prompted to weigh and arrange the chests. There is only one round per playthrough.\n",
    "         This event provides information about the game characteristics of the round (i.e. resources, objectives, setup). \n",
    "         It is used in calculating things like time spent in a round (for speed and accuracy), attempts at \n",
    "        solving a round, and the number of rounds the player has visited (exposures).']\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def event_code_2025(self):\n",
    "        \"\"\"\n",
    "        ['The reset dinosaurs event is triggered when the player has placed the last dinosaur, \n",
    "        but not all dinosaurs are in the correct position. \n",
    "        This event provides information about the game characteristics of the round (i.e. resources, objectives, setup). \n",
    "        It is used to indicate a significant change in state during play.']\n",
    "        \n",
    "        This event is used for calculating time spent in a round and \n",
    "        the number of rounds the player has completed (completion).\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def event_code_2030(self):\n",
    "        \"\"\"\n",
    "        ['The beat round event is triggered when the player finishes a round by filling the jar.\n",
    "         This event is used for calculating time spent in a round and\n",
    "          the number of rounds the player has completed (completion).']\n",
    "\n",
    "        \"\"\"\n",
    "        if 2030 in self.unique_event_codes:\n",
    "            rounds = self.user_sample[self.user_sample.event_code == 2030]\n",
    "\n",
    "            round_duration = rounds[\"duration\"].values\n",
    "            \n",
    "            features_2030 = FeaturesGeneration(round_duration, \"_2030\")\n",
    "            self.Event_features.update(features_2030.copy())\n",
    "            \n",
    "\n",
    "            try:\n",
    "                round_misses = rounds[\"misses\"].values\n",
    "\n",
    "                features_2030 = FeaturesGeneration(round_misses, \"_2030_misses\")\n",
    "                self.Event_features.update(features_2030.copy())\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    def event_code_2035(self):\n",
    "        \"\"\"\n",
    "        ['The finish filling tub event is triggered after the player finishes filling up the tub. \n",
    "        It is used to separate a section of gameplay that is different from the estimation section of the game.']\n",
    "        \"\"\"\n",
    "        if 2035 in self.unique_event_codes:\n",
    "            rounds = self.user_sample[self.user_sample.event_code == 2035]\n",
    "\n",
    "            round_duration = rounds[\"duration\"].values\n",
    "            features_2035 = FeaturesGeneration(round_duration, \"_2035\")\n",
    "            self.Event_features.update(features_2035.copy())\n",
    "    \n",
    "    def event_code_2040(self):\n",
    "        \"\"\"\n",
    "        ['The start level event is triggered when a new level begins \n",
    "        (at the same time as the start round event for the first round in the level). \n",
    "        This event is used for calculating time spent in a level (for speed and accuracy), \n",
    "        and the number of levels the player has completed (completion).']\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def event_code_2050(self):\n",
    "        \"\"\"\n",
    "        ['The beat level event is triggered when a level has been completed and \n",
    "        the player has cleared all rounds in the current layout (occurs at the same time as \n",
    "        the beat round event for the last round in the previous level). This event is used for \n",
    "        calculating time spent in a level (for speed and accuracy), \n",
    "        and the number of levels the player has completed (completion).']\n",
    "        \"\"\"\n",
    "        if 2050 in self.unique_event_codes:\n",
    "            level = self.user_sample[self.user_sample.event_code == 2050]\n",
    "\n",
    "            level_duration = level[\"duration\"].values\n",
    "            features_2050 = FeaturesGeneration(level_duration, \"_2050\")\n",
    "            self.Event_features.update(features_2050.copy())\n",
    "\n",
    "\n",
    "    def event_code_2060(self):\n",
    "        \"\"\"\n",
    "        ['The start tutorial event is triggered at the start of the tutorial. \n",
    "        It is used in calculating time spent in the tutorial.']\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def event_code_2070(self):\n",
    "        \"\"\"\n",
    "        ['The beat round event is triggered when the player finishes the tutorial. \n",
    "        This event is used for calculating time spent in the tutorial.']\n",
    "        \"\"\"\n",
    "        if 2070 in self.unique_event_codes:\n",
    "            tutorial = self.user_sample[self.user_sample.event_code == 2070]\n",
    "\n",
    "            tutorial_duration = tutorial[\"duration\"].values\n",
    "            \n",
    "            features_2070 = FeaturesGeneration(tutorial_duration, \"_2070\")\n",
    "            self.Event_features.update(features_2070.copy())\n",
    "    \n",
    "    def event_code_2075(self):\n",
    "        \"\"\"\n",
    "        ['The beat round event is triggered when the player skips the tutorial by clicking on the skip button.\n",
    "         This event is used for calculating time spent in the tutorial.']\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def event_code_2080(self):\n",
    "        \"\"\"\n",
    "        ['The movie started event triggers when an intro or outro movie starts to play. \n",
    "        It identifies the movie being played. This is used to determine how long players \n",
    "        spend watching the movies (more relevant after the first play \n",
    "        through when the skip option is available).']\n",
    "        \"\"\"\n",
    "        if 2080 in self.unique_event_codes:\n",
    "\n",
    "            movie = self.user_sample[self.user_sample.event_code == 2080]\n",
    "\n",
    "            movie_duration = movie[\"duration\"].values\n",
    "            \n",
    "            features_2080 = FeaturesGeneration(movie_duration, \"_2080\")\n",
    "            self.Event_features.update(features_2080.copy())\n",
    "\n",
    "    def event_code_2081(self):\n",
    "        \"\"\"\n",
    "        ['The movie started event triggers when an intro or outro movie starts to play. \n",
    "        It identifies the movie being played. This is used to determine how long players \n",
    "        spend watching the movies (more relevant after the first play \n",
    "        through when the skip option is available).']\n",
    "        \"\"\"\n",
    "        if 2081 in self.unique_event_codes:\n",
    "\n",
    "            movie = self.user_sample[self.user_sample.event_code == 2081]\n",
    "\n",
    "            self.Event_features[\"accu_movie_skiping_count_2081\"] = movie[\"duration\"].count()\n",
    "    \n",
    "    def event_code_2083(self):\n",
    "        \"\"\"\n",
    "        ['The movie started event triggers when an intro or outro movie starts to play. \n",
    "        It identifies the movie being played. This is used to determine how long players \n",
    "        spend watching the movies (more relevant after the first play \n",
    "        through when the skip option is available).']\n",
    "        \"\"\"\n",
    "        if 2083 in self.unique_event_codes:\n",
    "\n",
    "            movie = self.user_sample[self.user_sample.event_code == 2083]\n",
    "\n",
    "            movie_duration = movie[\"duration\"].values\n",
    "            features_2083 = FeaturesGeneration(movie_duration, \"_2083\")\n",
    "            self.Event_features.update(features_2083.copy())\n",
    "    \n",
    "    def event_code_3010(self):\n",
    "        \"\"\"\n",
    "        ['The system-initiated instruction event occurs when the game delivers instructions to the player.\n",
    "         It contains information that describes the content of the instruction. This event differs from events 3020\n",
    "          and 3021 as it captures instructions that are not given in response to player action. \n",
    "          These events are used to determine the effectiveness of the instructions. We can answer questions like,\n",
    "         \"did players who received instruction X do better than those who did not?\"']\n",
    "        \"\"\"\n",
    "        if 3010 in self.unique_event_codes:\n",
    "\n",
    "            instruction = self.user_sample[self.user_sample.event_code == 3010]\n",
    "\n",
    "            instruction_duration = instruction[\"total_duration\"].values\n",
    "            \n",
    "            features_3010 = FeaturesGeneration(instruction_duration, \"_3010\")\n",
    "            self.Event_features.update(features_3010.copy())\n",
    "\n",
    "    def event_code_3020(self):\n",
    "        \"\"\"\n",
    "        ['The system-initiated feedback (Incorrect) event occurs when the game starts delivering feedback \n",
    "        to the player in response to an incorrect round attempt (pressing the go button with the incorrect answer). \n",
    "        It contains information that describes the content of the instruction. These events are used to determine \n",
    "        the effectiveness of the feedback. We can answer questions like \n",
    "        \"did players who received feedback X do better than those who did not?\"']\n",
    "        \"\"\"\n",
    "        if 3020 in self.unique_event_codes:\n",
    "\n",
    "            Incorrect = self.user_sample[self.user_sample.event_code == 3020]\n",
    "\n",
    "            Incorrect_duration = Incorrect[\"total_duration\"].values\n",
    "            \n",
    "            features_3020 = FeaturesGeneration(Incorrect_duration, \"_3020\")\n",
    "            self.Event_features.update(features_3020.copy())\n",
    "            \n",
    "            self.Event_features[\"accu_Incorrect_media_type_3020_count_\"] = Incorrect[\"media_type\"].count()\n",
    "    \n",
    "\n",
    "    def event_code_3021(self):\n",
    "        \"\"\"\n",
    "        ['The system-initiated feedback (Correct) event occurs when the game \n",
    "        starts delivering feedback to the player in response to a correct round attempt \n",
    "        (pressing the go button with the correct answer). It contains information that describes the\n",
    "         content of the instruction, and will likely occur in conjunction with a beat round event. \n",
    "         These events are used to determine the effectiveness of the feedback. We can answer questions like, \n",
    "        \"did players who received feedback X do better than those who did not?\"']\n",
    "        \"\"\"\n",
    "        if 3021 in self.unique_event_codes:\n",
    "\n",
    "            Correct = self.user_sample[self.user_sample.event_code == 3021]\n",
    "\n",
    "            Correct_duration = Correct[\"total_duration\"].values\n",
    "            features_3021 = FeaturesGeneration(Correct_duration, \"_3021\")\n",
    "            self.Event_features.update(features_3021.copy())\n",
    "            \n",
    "            self.Event_features[\"accu_Correct_media_type_3021_count_\"] = Correct[\"media_type\"].count()\n",
    "\n",
    "    def event_code_3110(self):\n",
    "        \"\"\"\n",
    "        ['The end of system-initiated instruction event occurs when the game finishes \n",
    "        delivering instructions to the player. It contains information that describes the\n",
    "         content of the instruction including duration. These events are used to determine the \n",
    "         effectiveness of the instructions and the amount of time they consume. We can answer questions like, \n",
    "        \"how much time elapsed while the game was presenting instruction?\"']\n",
    "        \"\"\"\n",
    "        if 3110 in self.unique_event_codes:\n",
    "\n",
    "            Instuction = self.user_sample[self.user_sample.event_code == 3110]\n",
    "\n",
    "            Instuction_duration = Instuction[\"duration\"].values\n",
    "            features_3110 = FeaturesGeneration(Instuction_duration, \"_3110\")\n",
    "            self.Event_features.update(features_3110.copy())\n",
    "            \n",
    "            self.Event_features[\"accu_Instuction_media_type_3110_count_\"] = Instuction[\"media_type\"].count()\n",
    "\n",
    "    def event_code_3120(self):\n",
    "        \"\"\"\n",
    "        ['The end of system-initiated feedback (Incorrect) event \n",
    "        occurs when the game finishes delivering feedback to the player in response\n",
    "         to an incorrect round attempt (pressing the go button with the incorrect answer). \n",
    "         It contains information that describes the content of the instruction. \n",
    "         These events are used to determine the effectiveness of the feedback. We can answer questions like,\n",
    "         “how much time elapsed while the game was presenting feedback?”']\n",
    "        \"\"\"\n",
    "        if 3120 in self.unique_event_codes:\n",
    "\n",
    "            IncorrectInstruction = self.user_sample[self.user_sample.event_code == 3120]\n",
    "\n",
    "            IncorrectInstruction_duration = IncorrectInstruction[\"duration\"].values\n",
    "            \n",
    "            features_3120 = FeaturesGeneration(IncorrectInstruction_duration, \"_3120\")\n",
    "            self.Event_features.update(features_3120.copy())\n",
    "            \n",
    "            self.Event_features[\"accu_IncorrectInstruction_media_type_3120_count_\"] = IncorrectInstruction[\"media_type\"].count()\n",
    "\n",
    "    def event_code_3121(self):\n",
    "        \"\"\"\n",
    "        ['The end of system-initiated feedback (Correct) event \n",
    "        occurs when the game finishes delivering feedback to the player in response\n",
    "         to an incorrect round attempt (pressing the go button with the incorrect answer). \n",
    "         It contains information that describes the content of the instruction. \n",
    "         These events are used to determine the effectiveness of the feedback. We can answer questions like,\n",
    "         “how much time elapsed while the game was presenting feedback?”']\n",
    "        \"\"\"\n",
    "        if 3121 in self.unique_event_codes:\n",
    "\n",
    "            CorrectInstruction = self.user_sample[self.user_sample.event_code == 3121]\n",
    "\n",
    "            CorrectInstruction_duration = CorrectInstruction[\"duration\"].values\n",
    "\n",
    "            features_3121 = FeaturesGeneration(CorrectInstruction_duration, \"_3121\")\n",
    "            self.Event_features.update(features_3121.copy())\n",
    "            \n",
    "            self.Event_features[\"accu_CorrectInstruction_media_type_3121_count_\"] = CorrectInstruction[\"media_type\"].count()\n",
    "\n",
    "\n",
    "    def event_code_4010(self):\n",
    "        \"\"\"\n",
    "\n",
    "        ['This event occurs when the player clicks to start \n",
    "        the game from the starting screen.']\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "    \n",
    "    def event_code_4020(self):\n",
    "        \"\"\"\n",
    "        ['This event occurs when the player \n",
    "        clicks a group of objects. It contains information \n",
    "        about the group clicked, the state of the game, and the\n",
    "         correctness of the action. This event is \n",
    "         to diagnose player strategies and understanding.']\n",
    "\n",
    "         It contains information about the state of the game and the correctness of the action. This event is used \n",
    "         to diagnose player strategies and understanding.\n",
    "        \"\"\"\n",
    "        \n",
    "        if 4020 in self.unique_event_codes:\n",
    "\n",
    "            event_data = self.user_sample[self.user_sample.event_code == 4020]\n",
    "\n",
    "            true_attempts = event_data[event_data.correct == True]['correct'].count()\n",
    "            false_attempts = event_data[event_data.correct == False]['correct'].count()\n",
    "            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "\n",
    "            self.Event_features[\"accu_True_attempts_4020_\"] = true_attempts\n",
    "            self.Event_features[\"accu_False_attempts_4020_\"] = false_attempts\n",
    "            self.Event_features[\"accu_Accuracy_attempts_4020_\"] = accuracy\n",
    "\n",
    "    def event_code_4021(self):\n",
    "        pass\n",
    "    \n",
    "    def event_code_4022(self):\n",
    "        pass\n",
    "\n",
    "    def event_code_4025(self):\n",
    "        pass\n",
    "\n",
    "    def event_code_4030(self):\n",
    "        pass\n",
    "\n",
    "    def event_code_4031(self):\n",
    "        pass\n",
    "\n",
    "    def event_code_4035(self):\n",
    "\n",
    "        if 4035 in self.unique_event_codes:\n",
    "\n",
    "            event_data = self.user_sample[self.user_sample.event_code == 4035]\n",
    "\n",
    "            self.Event_features[\"accu_wrong_place_count_4035_\"] = len(event_data)\n",
    "\n",
    "            try:\n",
    "                wrong_place = event_data[\"duration\"].values\n",
    "\n",
    "                features_4035 = FeaturesGeneration(wrong_place, \"_4035\")\n",
    "                self.Event_features.update(features_4035.copy())\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    \n",
    "    def event_code_4040(self):\n",
    "        pass\n",
    "\n",
    "    def event_code_4045(self):\n",
    "        pass\n",
    "\n",
    "    def event_code_4050(self):\n",
    "        pass\n",
    "\n",
    "    def event_code_4070(self):\n",
    "        \"\"\"\n",
    "        \n",
    "        ['This event occurs when the player clicks on\n",
    "            something that isn’t covered elsewhere. \n",
    "            It can be useful in determining if there are\n",
    "            attractive distractions (things the player think\n",
    "            should do something, but don’t) in the game, or\n",
    "            diagnosing players \n",
    "            who are having mechanical difficulties (near misses).']\n",
    "        \"\"\"\n",
    "        if 4070 in self.unique_event_codes:\n",
    "\n",
    "            event_data = self.user_sample[self.user_sample.event_code == 4070]\n",
    "            self.Event_features[\"accu_something_not_covered_count_4070_\"] = len(event_data)\n",
    "\n",
    "    def event_code_4080(self):\n",
    "\n",
    "        if 4080 in self.unique_event_codes:\n",
    "\n",
    "            event_data = self.user_sample[self.user_sample.event_code == 4080]\n",
    "\n",
    "            self.Event_features[\"accu_mouse_over_count_4080_\"] = len(event_data)\n",
    "\n",
    "            try:\n",
    "\n",
    "                dwell_time = event_data[\"dwell_time\"].values\n",
    "                \n",
    "                features_4080 = FeaturesGeneration(dwell_time, \"_4080\")\n",
    "                self.Event_features.update(features_4080.copy())\n",
    "            \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    def event_code_4090(self):\n",
    "        pass\n",
    "\n",
    "    def event_code_4095(self):\n",
    "        pass\n",
    "        \n",
    "    def event_code_4100(self):\n",
    "        \n",
    "        if 4100 in self.unique_event_codes:\n",
    "\n",
    "            event_data = self.user_sample[self.user_sample.event_code == 4100]\n",
    "\n",
    "            true_attempts = event_data[event_data.correct == True]['correct'].count()\n",
    "            false_attempts = event_data[event_data.correct == False]['correct'].count()\n",
    "            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "\n",
    "            self.Event_features[\"accu_True_attempts_4100_\"] = true_attempts\n",
    "            self.Event_features[\"accu_False_attempts_4100_\"] = false_attempts\n",
    "            self.Event_features[\"accu_Accuracy_attempts_4100_\"] = accuracy\n",
    "\n",
    "    def event_code_4110(self):\n",
    "        \n",
    "\n",
    "        if 4110 in self.unique_event_codes:\n",
    "\n",
    "            event_data = self.user_sample[self.user_sample.event_code == 4110]\n",
    "\n",
    "            true_attempts = event_data[event_data.correct == True]['correct'].count()\n",
    "            false_attempts = event_data[event_data.correct == False]['correct'].count()\n",
    "            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "\n",
    "            self.Event_features[\"accu_True_attempts_4110_\"+self.user_sample_title] = true_attempts\n",
    "            self.Event_features[\"accu_False_attempts_4110_\"+self.user_sample_title] = false_attempts\n",
    "            self.Event_features[\"accu_Accuracy_attempts_4110_\"+self.user_sample_title] = accuracy\n",
    "            \n",
    "\n",
    "    def event_code_4220(self):\n",
    "        pass\n",
    "\n",
    "    def event_code_4230(self):\n",
    "        pass\n",
    "\n",
    "    def event_code_4235(self):\n",
    "        pass\n",
    "\n",
    "    def event_code_5000(self):\n",
    "        pass\n",
    "\n",
    "    def event_code_5010(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(train, test, unique_data):\n",
    "    compiled_train = []\n",
    "    compiled_test = []\n",
    "    \n",
    "    \n",
    "    if os.path.exists(\"../input/amma-reduce/amma_train.csv\"):\n",
    "        reduce_train_file = True\n",
    "        reduce_train = pd.read_csv(\"../input/amma-reduce/amma_train.csv\")\n",
    "    else:\n",
    "        for i, (ins_id, user_sample) in tqdm(enumerate(train.groupby(\"installation_id\", sort=False)), total=len(train.installation_id.unique())):\n",
    "\n",
    "            if \"Assessment\" in user_sample.type.unique():\n",
    "                temp_df = json_parser(user_sample, \"event_data\")\n",
    "                temp_df.sort_values(\"timestamp\", inplace=True)\n",
    "                temp_df.reset_index(inplace=True, drop=True)\n",
    "                temp_df[\"index\"] = temp_df.index.values\n",
    "                compiled_train.extend(get_data(temp_df, unique_data))\n",
    "\n",
    "        reduce_train = pd.DataFrame(compiled_train)\n",
    "\n",
    "    for i, (ins_id, user_sample) in tqdm(enumerate(test.groupby(\"installation_id\", sort=False)), total=len(test.installation_id.unique())):\n",
    "\n",
    "        if \"Assessment\" in user_sample.type.unique():\n",
    "            temp_df = json_parser(user_sample, \"event_data\")\n",
    "            temp_df.sort_values(\"timestamp\", inplace=True)\n",
    "            temp_df.reset_index(inplace=True, drop=True)\n",
    "            temp_df[\"index\"] = temp_df.index.values\n",
    "            compiled_test.append(get_data(temp_df,unique_data, test=True))\n",
    "\n",
    "    reduce_test = pd.DataFrame(compiled_test)\n",
    "\n",
    "    return reduce_train, reduce_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce_train.to_csv(\"amma_train.csv\", index=False)\n",
    "#reduce_test.to_csv(\"amma_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65c0b589be9e4b2691e6b7c018e277d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reduce_train, reduce_test = get_train_test(train, test, unique_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17690, 2143), (1000, 2143))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_train.shape , reduce_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17690, 2143)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_train = reduce_train[reduce_train.game_session.isin(train_labels.game_session.unique())]\n",
    "reduce_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_train.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in reduce_train.columns]\n",
    "reduce_test.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in reduce_test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem = list(set(reduce_train.columns).intersection(set(reduce_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_train = reduce_train[rem]\n",
    "reduce_test = reduce_test[rem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17690, 2143), (1000, 2143))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_train.shape, reduce_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce_test.to_csv(\"amma_test1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = reduce_train.copy()\n",
    "test = reduce_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataPreprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_features = []\n",
    "\n",
    "for colstart in ['skew', 'kstat', 'kurtosis','moment' ]:\n",
    "    new = reduce_train.columns[reduce_train.columns.str.startswith(colstart)]\n",
    "    useless_features.extend(new.tolist())\n",
    "\n",
    "reduce_train.drop(columns=useless_features, inplace=True)\n",
    "reduce_test.drop(columns=useless_features, inplace=True)\n",
    "\n",
    "# filling inf and NINF values with nan\n",
    "\n",
    "reduce_train.replace(np.inf, np.nan, inplace=True)\n",
    "reduce_test.replace(np.inf, np.nan, inplace=True)\n",
    "\n",
    "reduce_train.replace(np.NINF, np.nan, inplace=True)\n",
    "reduce_test.replace(np.NINF, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17690, 1562), (1000, 1562))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# droping duplicate columns\n",
    "\n",
    "def drop_duplicate_columns(train_df, test_df):\n",
    "    new_df = train_df.T.drop_duplicates()\n",
    "    new_df = new_df.T\n",
    "    train_df = train_df[new_df.columns]\n",
    "    test_df = test_df[new_df.columns]\n",
    "    return train_df, test_df\n",
    "\n",
    "reduce_train, reduce_test = drop_duplicate_columns(reduce_train, reduce_test)\n",
    "\n",
    "reduce_train.shape , reduce_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine = [reduce_train, reduce_test]\n",
    "\n",
    "object_info = pd.DataFrame()\n",
    "num_info = pd.DataFrame()\n",
    "\n",
    "for x in combine[0].columns:\n",
    "    # Missing Values Dataframe\n",
    "    if combine[0][x].isnull().any() == True:\n",
    "        object_info = object_info.append({'Column': x,'dtype': combine[0][x].dtypes,\n",
    "        'Count': combine[0][x].count().astype(int),\n",
    "        'Missing %':(combine[0][x].isnull().sum()/combine[0].shape[0])*100,\n",
    "        'Unique':len(combine[0][x].unique())},ignore_index=True)\n",
    "    # Custom Descriptive Statistics Table\n",
    "    if combine[0][x].dtype != \"object\" :\n",
    "        num_info = num_info.append({'Column': x, 'dtype': combine[0][x].dtypes, 'Count':\n",
    "        combine[0][x].count().astype(int), 'Missing %':(combine[0][x].isnull().sum()/combine[0].shape[0])*100,\n",
    "        'Unique': len(combine[0][x].unique()), 'Stdev':combine[0][x].std(),\n",
    "        'Mean':combine[0][x].mean(), 'Stdev':combine[0][x].std(),\n",
    "        'Variance':combine[0][x].var()},ignore_index=True)\n",
    "        \n",
    "object_info.sort_values(by=[\"Missing %\"], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values columns > 60 % : 361\n"
     ]
    }
   ],
   "source": [
    "Missing_values_cols = num_info[num_info[\"Missing %\"] > 60][\"Column\"]\n",
    "\n",
    "print(\"Number of missing values columns > 60 % :\", len(Missing_values_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "\n",
    "def reduce_mem_usage(df, use_float16=False):\n",
    "    \"\"\"\n",
    "    Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.\n",
    "    \"\"\"\n",
    "\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n",
    "\n",
    "    for col in df.columns:\n",
    "        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
    "            continue\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            #df[col] = df[col].astype(\"category\")\n",
    "            pass\n",
    "        \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n",
    "    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 211.57 MB\n",
      "Memory usage after optimization is: 91.07 MB\n",
      "Decreased by 57.0%\n",
      "Memory usage of dataframe is 11.92 MB\n",
      "Memory usage after optimization is: 4.96 MB\n",
      "Decreased by 58.4%\n"
     ]
    }
   ],
   "source": [
    "reduce_train = reduce_mem_usage(reduce_train)\n",
    "reduce_test = reduce_mem_usage(reduce_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17690, 1562), (1000, 1562))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_train.shape, reduce_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17690, 2547), (1000, 2547))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values as new features\n",
    "\n",
    "def missing_values_as_new_column(train_df, test_df):\n",
    "    for col in train_df.columns:\n",
    "        if train_df[col].isna().any():\n",
    "            train_df[\"Missing_value_\"+col] = np.where(train_df[col].isna(), 1, 0)\n",
    "            test_df[\"Missing_value_\"+col] = np.where(test_df[col].isna(), 1, 0)\n",
    "    return train_df, test_df\n",
    "\n",
    "reduce_train, reduce_test = missing_values_as_new_column(reduce_train, reduce_test)\n",
    "\n",
    "reduce_train.shape , reduce_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Missing_values_filled_cols = reduce_train.columns[reduce_train.columns.str.startswith(\"Missing_value_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "985"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Missing_values_filled_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 145 columns to remove.\n"
     ]
    }
   ],
   "source": [
    "# correlated_features\n",
    "\n",
    "threshold = 1\n",
    "\n",
    "corr_matrix = reduce_train.corr().abs()\n",
    "\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Select columns with correlations above threshold\n",
    "correlation_to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "print('There are %d columns to remove.' % (len(correlation_to_drop)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom fancyimpute import SoftImpute\\n\\n#get continuous features\\ncolnames_numerics_only = reduce_train.select_dtypes(include=np.number).columns.tolist()\\n\\n#impute missing values of continuous features using KNN\\nreduce_train[first_10] = SoftImpute(max_iters=3).fit_transform(reduce_train[first_10])\\nprint('missing values of continuous features imputed successfully')\\n\\n\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# impute missing values of continuous features using KNN\n",
    "\"\"\"\n",
    "from fancyimpute import SoftImpute\n",
    "\n",
    "#get continuous features\n",
    "colnames_numerics_only = reduce_train.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "#impute missing values of continuous features using KNN\n",
    "reduce_train[first_10] = SoftImpute(max_iters=3).fit_transform(reduce_train[first_10])\n",
    "print('missing values of continuous features imputed successfully')\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17690, 2547), (1000, 2547))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_train.shape, reduce_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17690, 2551), (1000, 2551))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_timestamp_features(df):\n",
    "    date_time = pd.to_datetime(df[\"timestamp_session\"])\n",
    "    df[\"day\"] = date_time.dt.day\n",
    "    df[\"month\"] = date_time.dt.month\n",
    "    df[\"week_day\"] = date_time.dt.weekday\n",
    "    df[\"hour\"] = date_time.dt.hour\n",
    "    return df\n",
    "\n",
    "reduce_train = extract_timestamp_features(reduce_train)\n",
    "reduce_test = extract_timestamp_features(reduce_test)\n",
    "\n",
    "reduce_train.shape , reduce_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_train_tree = reduce_train.copy()\n",
    "reduce_test_tree = reduce_test.copy()\n",
    "\n",
    "reduce_train_linear = reduce_train.copy()\n",
    "reduce_test_linear = reduce_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2545, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclude_cols = ['timestamp_session', 'installation_id', 'game_session']\n",
    "cat_cols = reduce_train_tree.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "num_cols = list(set(reduce_train_tree.columns) - set(cat_cols))\n",
    "cat_cols = list(set(cat_cols) - set(exclude_cols))\n",
    "\n",
    "len(num_cols) , len(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17690, 2551), (1000, 2551))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tree_based_models(train, test, columns_map):\n",
    "    \n",
    "    for col in columns_map:\n",
    "        list_of_values = list(set(train[col].unique()).union(set(test[col].unique())))\n",
    "        list_of_values_map = dict(zip(list_of_values, np.arange(len(list_of_values))))\n",
    "        train[col] = train[col].map(list_of_values_map)\n",
    "        test[col] = test[col].map(list_of_values_map)\n",
    "        \n",
    "    train.fillna(-999, inplace=True)\n",
    "    test.fillna(-999, inplace=True)\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "reduce_train_tree, reduce_test_tree = tree_based_models(reduce_train_tree, reduce_test_tree, columns_map=cat_cols)\n",
    "\n",
    "reduce_train_tree.shape , reduce_test_tree.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17690, 2595), (1000, 2595))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linear_based_models(train, test, cat_cols, numaric_cols):\n",
    "    \n",
    "    skewd_features = np.array(numaric_cols)[np.abs(skew(train[numaric_cols])) > 0.5]\n",
    "    \n",
    "    train[skewd_features] = np.log1p(train[skewd_features])\n",
    "    test[skewd_features] = np.log1p(test[skewd_features])\n",
    "    \n",
    "    for col in cat_cols:\n",
    "        try:\n",
    "            map_encoded = train[col].value_counts(normalize=True, dropna=False)\n",
    "            train[col+\"_Encoded\"] = train[col].map(map_encoded)\n",
    "            test[col+\"_Encoded\"] = test[col].map(map_encoded)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # One Hot Encoder\n",
    "    train = pd.get_dummies(train, columns=cat_cols, prefix=cat_cols)\n",
    "    test = pd.get_dummies(test, columns=cat_cols, prefix=cat_cols)\n",
    "    \n",
    "    rem = list(set(train.columns).intersection(set(test)))\n",
    "    \n",
    "    train = train[rem]\n",
    "    test = test[rem]\n",
    "    \n",
    "    train.replace(np.inf, np.nan, inplace=True)\n",
    "    test.replace(np.inf, np.nan, inplace=True)\n",
    "\n",
    "    train.replace(np.NINF, np.nan, inplace=True)\n",
    "    test.replace(np.NINF, np.nan, inplace=True)\n",
    "    \n",
    "    train.fillna(0, inplace=True)\n",
    "    test.fillna(0, inplace=True)\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "reduce_train_linear, reduce_test_linear = linear_based_models(reduce_train_linear, reduce_test_linear, cat_cols, num_cols)\n",
    "\n",
    "reduce_train_linear.drop(columns=['day', 'month', 'hour'], inplace=True)\n",
    "reduce_test_linear.drop(columns=['day', 'month', 'hour'], inplace=True)\n",
    "\n",
    "reduce_train_linear.shape , reduce_test_linear.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_with_labels(train, train_labels):\n",
    "    \n",
    "    train = train[train.game_session.isin(train_labels.game_session.unique())]\n",
    "    \n",
    "    tld = train_labels[['game_session', 'installation_id', 'num_correct','num_incorrect', 'accuracy', 'accuracy_group']]\n",
    "    final_train = pd.merge(tld, train, left_on=['game_session', 'installation_id'], right_on=['game_session','installation_id'], how='inner')\n",
    "    \n",
    "    final_train.sort_values('timestamp_session', inplace=True)\n",
    "    col_drop = tld.columns.values\n",
    "    col_drop = np.append(col_drop, 'timestamp_session')\n",
    "    \n",
    "    return final_train, col_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_tree, col_drop = merge_with_labels(reduce_train_tree, train_labels)\n",
    "\n",
    "final_train_linear, col_drop = merge_with_labels(reduce_train_linear, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove_Outliers\n",
    "\n",
    "def removeOutlier(df, cols):\n",
    "    indexes=[]\n",
    "    for col in tqdm(cols):\n",
    "        if (df[col].dtypes !='object'):\n",
    "            if df[col].nunique() > 100:\n",
    "                Q1 = df[col].quantile(q=0.01)\n",
    "                Q3 = df[col].quantile(q=0.99)\n",
    "                df2 = df[(df[col] < Q1/5) | (df[col] > 5*Q3)]\n",
    "                indexes.extend(df2.index.tolist())\n",
    "                \n",
    "    df = df.drop(index=indexes)\n",
    "    return df, indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2999, 615)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_ins, test_ins = train_test_split(final_train_tree.installation_id.unique(), test_size=0.17)\n",
    "len(train_ins) , len(test_ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14743, 2555), (2947, 2555))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hold_out_tree = final_train_tree[final_train_tree.installation_id.isin(test_ins)]\n",
    "final_train_tree = final_train_tree[final_train_tree.installation_id.isin(train_ins)]\n",
    "\n",
    "final_train_tree.shape, hold_out_tree.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1230, 2555)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def get_hold_out_set(df):\n",
    "\n",
    "    final_session = []\n",
    "    for ins_id, sample_df in df.groupby(\"installation_id\", sort=False):\n",
    "        \n",
    "        if len(sample_df) > 0:\n",
    "            fs = sample_df.game_session.values[-1]\n",
    "            final_session.append(fs)\n",
    "\n",
    "    last_df = df[df.game_session.isin(final_session)]\n",
    "\n",
    "    user_idx = []\n",
    "\n",
    "    for iid in set(df[\"installation_id\"]):\n",
    "        list_ = list(df[df[\"installation_id\"] == iid].index)\n",
    "\n",
    "        cur = random.choices(list_, k = 1)[0]\n",
    "        user_idx.append(cur)\n",
    "    \n",
    "    turncated_df = df.loc[user_idx]\n",
    "\n",
    "    final_hold_out = pd.concat([last_df, turncated_df])\n",
    "\n",
    "    return final_hold_out\n",
    "\n",
    "hold_out_tree = get_hold_out_set(hold_out_tree)\n",
    "\n",
    "hold_out_tree.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(930, 2555)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hold_out_tree.drop_duplicates(inplace=True)\n",
    "hold_out_tree.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14743, 2599), (2947, 2599))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hold_out_linear = final_train_linear[final_train_linear.installation_id.isin(test_ins)]\n",
    "final_train_linear = final_train_linear[final_train_linear.installation_id.isin(train_ins)]\n",
    "\n",
    "final_train_linear.shape, hold_out_linear.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(930, 2599)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hold_out_linear = hold_out_linear[hold_out_linear.game_session.isin(hold_out_tree.game_session.unique())]\n",
    "hold_out_linear.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qwk(a1, a2):\n",
    "    \"\"\"\n",
    "    Source: https://www.kaggle.com/c/data-science-bowl-2019/discussion/114133#latest-660168\n",
    "\n",
    "    :param a1:\n",
    "    :param a2:\n",
    "    :param max_rat:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    max_rat = 3\n",
    "    a1 = np.asarray(a1, dtype=int)\n",
    "    a2 = np.asarray(a2, dtype=int)\n",
    "\n",
    "    hist1 = np.zeros((max_rat + 1, ))\n",
    "    hist2 = np.zeros((max_rat + 1, ))\n",
    "\n",
    "    o = 0\n",
    "    for k in range(a1.shape[0]):\n",
    "        i, j = a1[k], a2[k]\n",
    "        hist1[i] += 1\n",
    "        hist2[j] += 1\n",
    "        o +=  (i - j) * (i - j)\n",
    "\n",
    "    e = 0\n",
    "    for i in range(max_rat + 1):\n",
    "        for j in range(max_rat + 1):\n",
    "            e += hist1[i] * hist2[j] * (i - j) * (i - j)\n",
    "\n",
    "    e = e / a1.shape[0]\n",
    "\n",
    "    return 1 - o / e\n",
    "\n",
    "def confusion_matrix1(rater_a, rater_b, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the confusion matrix between rater's ratings\n",
    "    \"\"\"\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(rater_a + rater_b)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(rater_a + rater_b)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    conf_mat = [[0 for i in range(num_ratings)]\n",
    "                for j in range(num_ratings)]\n",
    "    for a, b in zip(rater_a, rater_b):\n",
    "        first = int(a - min_rating)\n",
    "        second = int(b - min_rating)\n",
    "        #print(conf_mat[0][0])\n",
    "        conf_mat[first][second] += 1\n",
    "    return conf_mat\n",
    "\n",
    "def histogram(ratings, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the counts of each type of rating that a rater made\n",
    "    \"\"\"\n",
    "    if min_rating is None:\n",
    "        min_rating = min(ratings)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(ratings)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    hist_ratings = [0 for x in range(num_ratings)]\n",
    "    for r in ratings:\n",
    "        second = int(r - min_rating)\n",
    "        hist_ratings[second] += 1\n",
    "    return hist_ratings\n",
    "\n",
    "def quadratic_weighted_kappa(y, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the quadratic weighted kappa\n",
    "    axquadratic_weighted_kappa calculates the quadratic weighted kappa\n",
    "    value, which is a measure of inter-rater agreement between two raters\n",
    "    that provide discrete numeric ratings.  Potential values range from -1\n",
    "    (representing complete disagreement) to 1 (representing complete\n",
    "    agreement).  A kappa value of 0 is expected if all agreement is due to\n",
    "    chance.\n",
    "    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n",
    "    each correspond to a list of integer ratings.  These lists must have the\n",
    "    same length.\n",
    "    The ratings should be integers, and it is assumed that they contain\n",
    "    the complete range of possible ratings.\n",
    "    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n",
    "    is the minimum possible rating, and max_rating is the maximum possible\n",
    "    rating\n",
    "    \"\"\"\n",
    "    rater_a = y\n",
    "    rater_b = y_pred\n",
    "    min_rating=None\n",
    "    max_rating=None\n",
    "    rater_a = np.array(rater_a, dtype=int)\n",
    "    rater_b = np.array(rater_b, dtype=int)\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(min(rater_a), min(rater_b))\n",
    "    if max_rating is None:\n",
    "        max_rating = max(max(rater_a), max(rater_b))\n",
    "        \n",
    "    conf_mat = confusion_matrix1(rater_a, rater_b,\n",
    "                                min_rating, max_rating)\n",
    "    num_ratings = len(conf_mat)\n",
    "    num_scored_items = float(len(rater_a))\n",
    "\n",
    "    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n",
    "    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n",
    "\n",
    "    numerator = 0.0\n",
    "    denominator = 0.0\n",
    "\n",
    "    for i in range(num_ratings):\n",
    "        for j in range(num_ratings):\n",
    "            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n",
    "                              / num_scored_items)\n",
    "            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n",
    "            numerator += d * conf_mat[i][j] / num_scored_items\n",
    "            denominator += d * expected_count / num_scored_items\n",
    "\n",
    "    return (1.0 - numerator / denominator)\n",
    "\n",
    "\n",
    "def compression_distance(x,y,l_x=None,l_y=None):\n",
    "    if x==y:\n",
    "        return 0\n",
    "    x_b = x.encode('utf-8')\n",
    "    y_b = y.encode('utf-8')\n",
    "    if l_x is None:\n",
    "        l_x = len(lzma.compress(x_b))\n",
    "        l_y = len(lzma.compress(y_b))\n",
    "    l_xy = len(lzma.compress(x_b+y_b))\n",
    "    l_yx = len(lzma.compress(y_b+x_b))\n",
    "    dist = (min(l_xy,l_yx)-min(l_x,l_y))/max(l_x,l_y)\n",
    "    return dist\n",
    "\n",
    "def get_scores(std_true, y_true):\n",
    "    best_diff = np.inf\n",
    "    combs = list(combinations_with_replacement([1,2,3,4],3)) + list(combinations_with_replacement([1,2,3,4],4)) + list(combinations_with_replacement([1,2,3,4],5))\n",
    "    for item in combs:\n",
    "        if np.median(item) == y_true:\n",
    "            diff = np.abs(np.std(item) - std_true)\n",
    "            if diff < best_diff:\n",
    "                best_diff = diff\n",
    "                best_match = list(item)\n",
    "                if best_diff < 1e-8:\n",
    "                    break\n",
    "    return best_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def very_border_acc(pred_true, y):\n",
    "    pred = pred_true.copy()\n",
    "    best_score = -999\n",
    "    \n",
    "    for k1 in tqdm(np.arange(0.5,1.5, 0.01)):\n",
    "        c1 = round(k1,2)\n",
    "        for k2 in np.arange(1.1,2.1, 0.01):\n",
    "            c2 = round(k2,2)\n",
    "            for k3 in np.arange(2.0,2.5, 0.01):\n",
    "                c3 = round(k3,2)\n",
    "                if c1 < c2 and c1 < c3 and c2 < c3:\n",
    "                    #print(c1, c2, c3)\n",
    "                    tmp_pred = pred.copy()\n",
    "                    tmp_pred[tmp_pred <= c1] = 0\n",
    "                    tmp_pred[np.where(np.logical_and(tmp_pred > c1, tmp_pred <= c2))] = 1\n",
    "                    tmp_pred[np.where(np.logical_and(tmp_pred > c2, tmp_pred <= c3))] = 2\n",
    "                    tmp_pred[tmp_pred > c3] = 3\n",
    "                    score = quadratic_weighted_kappa(y, tmp_pred)\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        #print(c1, c2, c3)\n",
    "                        best_coef = [c1, c2, c3]\n",
    "                        best_pred = tmp_pred.copy()\n",
    "    return best_pred, best_coef, best_score\n",
    "\n",
    "def very_border_acc_cv(pred_true, y):\n",
    "    pred = pred_true.copy()\n",
    "    best_score = -999\n",
    "    \n",
    "    for k1 in np.arange(0.5,1.5, 0.1):\n",
    "        c1 = round(k1,2)\n",
    "        for k2 in np.arange(1.1,2.1, 0.1):\n",
    "            c2 = round(k2,2)\n",
    "            for k3 in np.arange(2.0,2.5, 0.1):\n",
    "                c3 = round(k3,2)\n",
    "                if c1 < c2 and c1 < c3 and c2 < c3:\n",
    "                    #print(c1, c2, c3)\n",
    "                    tmp_pred = pred.copy()\n",
    "                    tmp_pred[tmp_pred <= c1] = 0\n",
    "                    tmp_pred[np.where(np.logical_and(tmp_pred > c1, tmp_pred <= c2))] = 1\n",
    "                    tmp_pred[np.where(np.logical_and(tmp_pred > c2, tmp_pred <= c3))] = 2\n",
    "                    tmp_pred[tmp_pred > c3] = 3\n",
    "                    score = quadratic_weighted_kappa(y, tmp_pred)\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        #print(c1, c2, c3)\n",
    "                        best_coef = [c1, c2, c3]\n",
    "                        best_pred = tmp_pred.copy()\n",
    "    return best_pred, best_coef, best_score\n",
    "\n",
    "# qwk optimize coefficients\n",
    "\n",
    "class OptimizedRounder(object):\n",
    "    def __init__(self, init_coef):\n",
    "        self.init_coef_ = init_coef\n",
    "        self.coef_ = 0\n",
    "    \n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        X_p = X.copy()\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0]  and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            else:\n",
    "                X_p[i] = 3\n",
    "        \n",
    "        ll = quadratic_weighted_kappa(y, X_p)\n",
    "        return -ll\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        \n",
    "        initial_coef = self.init_coef_\n",
    "        \n",
    "        self.coef_ = spoptimize.minimize(loss_partial, initial_coef, method=\"nelder-mead\")\n",
    "        \n",
    "    def predict(self, X, coef):\n",
    "        X_p = X.copy()\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            else:\n",
    "                X_p[i] = 3\n",
    "        return X_p\n",
    "    \n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']\n",
    "    \n",
    "\n",
    "def apply_border(pred, coefs):\n",
    "    c1, c2, c3 = coefs[0], coefs[1], coefs[2]\n",
    "    \n",
    "    tmp_pred = pred.copy()\n",
    "    \n",
    "    tmp_pred[tmp_pred <= c1] = 0\n",
    "    tmp_pred[np.where(np.logical_and(tmp_pred > c1, tmp_pred <= c2))] = 1\n",
    "    tmp_pred[np.where(np.logical_and(tmp_pred > c2, tmp_pred <= c3))] = 2\n",
    "    tmp_pred[tmp_pred > c3] = 3\n",
    "    \n",
    "    return tmp_pred.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "def linear_models():\n",
    "    \n",
    "    #ridge = Ridge(alpha=84.0, max_iter=50000)\n",
    "    \n",
    "    lasso = linear_model.Lasso(alpha=0.006, max_iter=50000)\n",
    "    \n",
    "    elasticNet = ElasticNet(alpha=0.006, l1_ratio=0.8, max_iter=50000)\n",
    "    \n",
    "    #kernal = KernelRidge()\n",
    "    \n",
    "    #svmr = svm.SVR()\n",
    "    \n",
    "    liner = linear_model.LinearRegression()\n",
    "    \n",
    "    brg = linear_model.BayesianRidge(n_iter=50000)\n",
    "    \n",
    "    return [[\"Lasso\", lasso], [\"elasticNet\", elasticNet], [\"BayesianRidge\", brg]]\n",
    "    \n",
    "    #return [[\"Linear\" , liner]]\n",
    "\n",
    "model_list = linear_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Base_Model(object):\n",
    "\n",
    "    def __init__(self, train, hold_out, test, col_drop):\n",
    "        self.train = train\n",
    "        self.hold_out = hold_out\n",
    "        self.test = test\n",
    "        self.drop_cols = col_drop\n",
    "\n",
    "    def get_linear_based_data(self):\n",
    "        \n",
    "        rbSc = MinMaxScaler()\n",
    "        train_x = self.train.drop(columns=self.drop_cols)\n",
    "\n",
    "        x_train = rbSc.fit_transform(self.train.drop(columns=self.drop_cols))\n",
    "        y_train = self.train[\"accuracy_group\"]\n",
    "\n",
    "        x_hold = rbSc.transform(self.hold_out[train_x.columns])\n",
    "        y_hold = self.hold_out[\"accuracy_group\"]\n",
    "\n",
    "        x_test = rbSc.transform(self.test[train_x.columns])\n",
    "\n",
    "        return x_train, y_train, x_hold, y_hold, x_test\n",
    "    \n",
    "    def get_tree_based_data(self):\n",
    "        \n",
    "\n",
    "        x_train = self.train.drop(columns=self.drop_cols)\n",
    "        y_train = self.train[\"accuracy_group\"]\n",
    "\n",
    "        x_hold = self.hold_out[x_train.columns]\n",
    "        y_hold = self.hold_out[\"accuracy_group\"]\n",
    "\n",
    "        x_test = self.test[x_train.columns]\n",
    "\n",
    "        return x_train, y_train, x_hold, y_hold, x_test\n",
    "        \n",
    "    def get_scores(self, train_pred, y_train, hold_pred, y_hold, test_pred):\n",
    "\n",
    "        print(\"\\n\")\n",
    "        print(\"** Train RMSE : \", mean_squared_error(y_train, train_pred))\n",
    "        print(\"** Hold  RMSE : \", mean_squared_error(y_hold, hold_pred))\n",
    "        print(\"\\n\")\n",
    "\n",
    "        train_best_pred, train_best_coef, train_best_score = very_border_acc_cv(train_pred, y_train)\n",
    "        print(\"Train Best_Score : \", train_best_score)\n",
    "        print(\"Train Best_Coef : \", train_best_coef)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        opt = OptimizedRounder(train_best_coef)\n",
    "        opt.fit(train_pred, y_train)\n",
    "        coefficients = opt.coefficients()\n",
    "\n",
    "        print(\"Optmized Coefficients : \", coefficients)\n",
    "\n",
    "        train_best_pred = opt.predict(train_pred, coefficients)\n",
    "        print(\"Optimized Train qwk : \", qwk(train_best_pred, y_train))\n",
    "\n",
    "\n",
    "        hold_best_pred, hold_best_coef, hold_best_score = very_border_acc_cv(hold_pred, y_hold)\n",
    "        print(\"Hold Best_Score : \", hold_best_score)\n",
    "        print(\"Hold Best_Coef : \", hold_best_coef)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "\n",
    "        hold_best_pred_train = opt.predict(hold_pred, coefficients)\n",
    "        print(\"\\n\")\n",
    "        print(\"Hold QWK Train_Coef : \", qwk(hold_best_pred_train, y_hold))\n",
    "\n",
    "        test_best_pred = opt.predict(test_pred, coefficients)\n",
    "        \n",
    "        opt = OptimizedRounder(hold_best_coef)\n",
    "        opt.fit(hold_pred, y_hold)\n",
    "        coefficients = opt.coefficients()\n",
    "        \n",
    "        hold_best_pred = opt.predict(hold_pred, coefficients)\n",
    "        \n",
    "        test_best_pred_hold = opt.predict(test_pred, coefficients)\n",
    "        \n",
    "        train_best_pred_hold = opt.predict(train_pred, coefficients)\n",
    "\n",
    "        return train_best_pred, train_best_pred_hold, hold_best_pred_train, hold_best_pred,test_best_pred, test_best_pred_hold\n",
    "\n",
    "\n",
    "    def Lgb_Model(self,x_train, y_train, x_hold, y_hold, x_test):\n",
    "\n",
    "        lgb_params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'learning_rate': 0.005,\n",
    "            'subsample': 0.33577567174,\n",
    "            'colsample_bytree': 0.88885216205885169,\n",
    "            'min_split_gain': 0.006,\n",
    "            'min_child_samples': 157,\n",
    "            'min_child_weight': 0.1,\n",
    "            'max_depth': -1,\n",
    "            'n_estimators': 10000,\n",
    "            'num_leaves': 17,\n",
    "            'silent': -1,\n",
    "            'verbose': -1,\n",
    "            #'max_depth': 15,\n",
    "            'random_state': 2019,\n",
    "            'reg_lambda' : 50,\n",
    "            'reg_alpha' : 0\n",
    "        }\n",
    "\n",
    "        model = lgb.LGBMRegressor(**lgb_params)\n",
    "        model.fit(\n",
    "            x_train, y_train,\n",
    "            eval_set=[(x_hold, y_hold)],\n",
    "            eval_metric='rmse',\n",
    "            verbose=100,\n",
    "            early_stopping_rounds=300\n",
    "        )\n",
    "\n",
    "        train_pred = model.predict(x_train, num_iteration=model.best_iteration_)\n",
    "        hold_pred = model.predict(x_hold, num_iteration=model.best_iteration_)\n",
    "        test_pred = model.predict(x_test, num_iteration=model.best_iteration_)\n",
    "\n",
    "        print(\"-------- Model : LGB ---------\")\n",
    "\n",
    "        train_best_pred, train_best_pred_hold, hold_best_pred_train, hold_best_pred,test_best_pred, test_best_pred_hold = self.get_scores(train_pred, y_train, hold_pred, y_hold, test_pred)\n",
    "\n",
    "        return_dict = {\n",
    "            \"train_pred\": train_pred,\n",
    "            \"hold_pred\" : hold_pred,\n",
    "            \"test_pred\" : test_pred,\n",
    "            \"train_best_pred\" : train_best_pred,\n",
    "            \"train_best_pred_hold\" : train_best_pred_hold,\n",
    "            \"hold_best_pred_train\" : hold_best_pred_train,\n",
    "            \"hold_best_pred\" : hold_best_pred,\n",
    "            \"test_best_pred\" : test_best_pred,\n",
    "            \"test_best_pred_hold\": test_best_pred_hold\n",
    "        }\n",
    "\n",
    "        return return_dict\n",
    "    \n",
    "    def Catb_Model(self,x_train, y_train, x_hold, y_hold, x_test):\n",
    "\n",
    "        params = {\n",
    "            'loss_function': 'RMSE',\n",
    "            'task_type': \"CPU\",\n",
    "            'iterations': 5000,\n",
    "            'od_type': \"Iter\",\n",
    "            'depth': 10,\n",
    "            'colsample_bylevel': 0.5, \n",
    "            'early_stopping_rounds': 150,\n",
    "            'l2_leaf_reg': 18,\n",
    "            'random_seed': 42,\n",
    "            'use_best_model': True\n",
    "        }\n",
    "\n",
    "        model = CatBoostRegressor(**params)\n",
    "        model.fit(\n",
    "            x_train, y_train,\n",
    "            eval_set=[(x_hold, y_hold)],\n",
    "            verbose=100\n",
    "        )\n",
    "\n",
    "        train_pred = model.predict(x_train)\n",
    "        hold_pred = model.predict(x_hold)\n",
    "        test_pred = model.predict(x_test)\n",
    "\n",
    "        print(\"-------- Model : CatBoost ---------\")\n",
    "\n",
    "        train_best_pred, train_best_pred_hold, hold_best_pred_train, hold_best_pred,test_best_pred, test_best_pred_hold = self.get_scores(train_pred, y_train, hold_pred, y_hold, test_pred)\n",
    "\n",
    "        return_dict = {\n",
    "            \"train_pred\": train_pred,\n",
    "            \"hold_pred\" : hold_pred,\n",
    "            \"test_pred\" : test_pred,\n",
    "            \"train_best_pred\" : train_best_pred,\n",
    "            \"train_best_pred_hold\" : train_best_pred_hold,\n",
    "            \"hold_best_pred_train\" : hold_best_pred_train,\n",
    "            \"hold_best_pred\" : hold_best_pred,\n",
    "            \"test_best_pred\" : test_best_pred,\n",
    "            \"test_best_pred_hold\": test_best_pred_hold\n",
    "        }\n",
    "\n",
    "        return return_dict\n",
    "\n",
    "    \n",
    "    def Xgb_Model(self,x_train, y_train, x_hold, y_hold, x_test):\n",
    "\n",
    "        params = {\n",
    "            'colsample_bytree': 0.8,                 \n",
    "            'learning_rate': 0.01,\n",
    "            'max_depth': 10,\n",
    "            'subsample': 1,\n",
    "            'objective':'reg:squarederror',\n",
    "            #'eval_metric':'rmse',\n",
    "            'min_child_weight':3,\n",
    "            'gamma':0.25,\n",
    "            'n_estimators':5000\n",
    "        }\n",
    "\n",
    "        train_set = xgb.DMatrix(x_train, y_train)\n",
    "        hold_set = xgb.DMatrix(x_hold, y_hold)\n",
    "        test_set = xgb.DMatrix(x_test)\n",
    "\n",
    "        model = xgb.train(params, train_set, \n",
    "                         num_boost_round=5000, evals=[(train_set, 'train'), (hold_set, 'hold')], \n",
    "                         verbose_eval=100, early_stopping_rounds=300)\n",
    "\n",
    "        train_pred = model.predict(train_set)\n",
    "        hold_pred = model.predict(hold_set)\n",
    "        test_pred = model.predict(test_set)\n",
    "\n",
    "        print(\"-------- Model : XGB ---------\")\n",
    "\n",
    "        train_best_pred, train_best_pred_hold, hold_best_pred_train, hold_best_pred,test_best_pred, test_best_pred_hold = self.get_scores(train_pred, y_train, hold_pred, y_hold, test_pred)\n",
    "\n",
    "        return_dict = {\n",
    "            \"train_pred\": train_pred,\n",
    "            \"hold_pred\" : hold_pred,\n",
    "            \"test_pred\" : test_pred,\n",
    "            \"train_best_pred\" : train_best_pred,\n",
    "            \"train_best_pred_hold\" : train_best_pred_hold,\n",
    "            \"hold_best_pred_train\" : hold_best_pred_train,\n",
    "            \"hold_best_pred\" : hold_best_pred,\n",
    "            \"test_best_pred\" : test_best_pred,\n",
    "            \"test_best_pred_hold\": test_best_pred_hold\n",
    "        }\n",
    "        \n",
    "        return return_dict\n",
    "\n",
    "    def Lasso_Model(self,x_train, y_train, x_hold, y_hold, x_test):\n",
    "\n",
    "        \n",
    "        model = linear_model.Lasso(alpha=0.006, max_iter=50000)\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        train_pred = model.predict(x_train)\n",
    "        hold_pred = model.predict(x_hold)\n",
    "        test_pred = model.predict(x_test)\n",
    "\n",
    "        print(\"-------- Model : Lasso ---------\")\n",
    "\n",
    "        train_best_pred, train_best_pred_hold, hold_best_pred_train, hold_best_pred,test_best_pred, test_best_pred_hold = self.get_scores(train_pred, y_train, hold_pred, y_hold, test_pred)\n",
    "\n",
    "        return_dict = {\n",
    "            \"train_pred\": train_pred,\n",
    "            \"hold_pred\" : hold_pred,\n",
    "            \"test_pred\" : test_pred,\n",
    "            \"train_best_pred\" : train_best_pred,\n",
    "            \"train_best_pred_hold\" : train_best_pred_hold,\n",
    "            \"hold_best_pred_train\" : hold_best_pred_train,\n",
    "            \"hold_best_pred\" : hold_best_pred,\n",
    "            \"test_best_pred\" : test_best_pred,\n",
    "            \"test_best_pred_hold\": test_best_pred_hold\n",
    "        }\n",
    "\n",
    "        return return_dict\n",
    "\n",
    "    def ElasticNet_Model(self,x_train, y_train, x_hold, y_hold, x_test):\n",
    "\n",
    "        \n",
    "        model = ElasticNet(alpha=0.006, l1_ratio=0.8, max_iter=50000)\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        train_pred = model.predict(x_train)\n",
    "        hold_pred = model.predict(x_hold)\n",
    "        test_pred = model.predict(x_test)\n",
    "\n",
    "        print(\"-------- Model : ElasticNet ---------\")\n",
    "\n",
    "        train_best_pred, train_best_pred_hold, hold_best_pred_train, hold_best_pred,test_best_pred, test_best_pred_hold = self.get_scores(train_pred, y_train, hold_pred, y_hold, test_pred)\n",
    "\n",
    "        return_dict = {\n",
    "            \"train_pred\": train_pred,\n",
    "            \"hold_pred\" : hold_pred,\n",
    "            \"test_pred\" : test_pred,\n",
    "            \"train_best_pred\" : train_best_pred,\n",
    "            \"train_best_pred_hold\" : train_best_pred_hold,\n",
    "            \"hold_best_pred_train\" : hold_best_pred_train,\n",
    "            \"hold_best_pred\" : hold_best_pred,\n",
    "            \"test_best_pred\" : test_best_pred,\n",
    "            \"test_best_pred_hold\": test_best_pred_hold\n",
    "        }\n",
    "        \n",
    "        return return_dict\n",
    "\n",
    "    def BayesianRidge_Model(self,x_train, y_train, x_hold, y_hold, x_test):\n",
    "\n",
    "        \n",
    "        model = linear_model.BayesianRidge(n_iter=50000)\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        train_pred = model.predict(x_train)\n",
    "        hold_pred = model.predict(x_hold)\n",
    "        test_pred = model.predict(x_test)\n",
    "\n",
    "        print(\"-------- Model : BayesianRidge ---------\")\n",
    "\n",
    "\n",
    "        train_best_pred, train_best_pred_hold, hold_best_pred_train, hold_best_pred,test_best_pred, test_best_pred_hold = self.get_scores(train_pred, y_train, hold_pred, y_hold, test_pred)\n",
    "\n",
    "        return_dict = {\n",
    "            \"train_pred\": train_pred,\n",
    "            \"hold_pred\" : hold_pred,\n",
    "            \"test_pred\" : test_pred,\n",
    "            \"train_best_pred\" : train_best_pred,\n",
    "            \"train_best_pred_hold\" : train_best_pred_hold,\n",
    "            \"hold_best_pred_train\" : hold_best_pred_train,\n",
    "            \"hold_best_pred\" : hold_best_pred,\n",
    "            \"test_best_pred\" : test_best_pred,\n",
    "            \"test_best_pred_hold\": test_best_pred_hold\n",
    "        }\n",
    "\n",
    "        return return_dict\n",
    "    \n",
    "    def HuberRegressor_Model(self,x_train, y_train, x_hold, y_hold, x_test):\n",
    "\n",
    "        \n",
    "        model = linear_model.HuberRegressor(max_iter=200)\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        train_pred = model.predict(x_train)\n",
    "        hold_pred = model.predict(x_hold)\n",
    "        test_pred = model.predict(x_test)\n",
    "\n",
    "        print(\"-------- Model : HuberRegressor ---------\")\n",
    "\n",
    "        train_best_pred, train_best_pred_hold, hold_best_pred_train, hold_best_pred,test_best_pred, test_best_pred_hold = self.get_scores(train_pred, y_train, hold_pred, y_hold, test_pred)\n",
    "\n",
    "        return_dict = {\n",
    "            \"train_pred\": train_pred,\n",
    "            \"hold_pred\" : hold_pred,\n",
    "            \"test_pred\" : test_pred,\n",
    "            \"train_best_pred\" : train_best_pred,\n",
    "            \"train_best_pred_hold\" : train_best_pred_hold,\n",
    "            \"hold_best_pred_train\" : hold_best_pred_train,\n",
    "            \"hold_best_pred\" : hold_best_pred,\n",
    "            \"test_best_pred\" : test_best_pred,\n",
    "            \"test_best_pred_hold\": test_best_pred_hold\n",
    "        }\n",
    "        \n",
    "        return return_dict\n",
    "    \n",
    "    def NN_Model(self,x_train, y_train, x_hold, y_hold, x_test):\n",
    "        X = x_train\n",
    "        y = y_train\n",
    "        def create_model(X, y):\n",
    "            nn = Sequential()\n",
    "\n",
    "            # layers\n",
    "            nn.add(Dense(units = 1024, kernel_initializer = 'uniform', activation = 'relu',\n",
    "                         input_dim = X.shape[1])),\n",
    "            nn.add(keras.layers.normalization.BatchNormalization()),\n",
    "            nn.add(keras.layers.Dropout(0.3)),\n",
    "            nn.add(Dense(units = 512, kernel_initializer = 'uniform', activation = 'relu')),\n",
    "            nn.add(keras.layers.normalization.BatchNormalization()),\n",
    "            nn.add(keras.layers.Dropout(0.3)),\n",
    "            nn.add(Dense(units = 256, kernel_initializer = 'uniform', activation = 'relu')),\n",
    "            nn.add(keras.layers.normalization.BatchNormalization()),\n",
    "            nn.add(keras.layers.Dropout(0.3)),\n",
    "            nn.add(Dense(units = 128, kernel_initializer = 'uniform', activation = 'relu')),\n",
    "            nn.add(keras.layers.normalization.BatchNormalization()),\n",
    "            nn.add(keras.layers.Dropout(0.3)),\n",
    "            nn.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu')),\n",
    "            nn.add(keras.layers.normalization.BatchNormalization()),\n",
    "            nn.add(keras.layers.Dropout(0.3)),\n",
    "            nn.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu')),\n",
    "            nn.add(keras.layers.normalization.BatchNormalization()),\n",
    "            nn.add(keras.layers.Dropout(0.3)),\n",
    "            nn.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu')),\n",
    "            nn.add(keras.layers.normalization.BatchNormalization()),\n",
    "            #nn.add(keras.layers.Dropout(0.3)),\n",
    "            #nn.add(Dense(units = 2, kernel_initializer = 'uniform', activation = 'relu')),\n",
    "            #nn.add(keras.layers.normalization.BatchNormalization()),\n",
    "            #nn.add(keras.layers.Dropout(0.3)),\n",
    "            nn.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'relu',\n",
    "                         kernel_regularizer=regularizers.l2(0.003)))\n",
    "\n",
    "            nn.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "            return nn\n",
    "        \n",
    "        model = create_model(x_train, y_train)\n",
    "    \n",
    "    \n",
    "        es = callbacks.EarlyStopping(monitor='val_loss', min_delta=0.001, patience=5, verbose=1,baseline=None, restore_best_weights=True)\n",
    "\n",
    "        rlr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                                          patience=3, min_lr=1e-6, verbose=1)\n",
    "\n",
    "\n",
    "        model.fit(x_train,y_train,\n",
    "                  validation_data=(x_hold, y_hold),\n",
    "                  verbose=1,\n",
    "                  batch_size=64,\n",
    "                  callbacks=[es, rlr],\n",
    "                  epochs=100\n",
    "            )\n",
    "\n",
    "        train_pred = model.predict(x_train)\n",
    "        train_pred = np.array([item for sublist in train_pred for item in sublist])\n",
    "        hold_pred = model.predict(x_hold)\n",
    "        hold_pred = np.array([item for sublist in hold_pred for item in sublist])\n",
    "        test_pred = model.predict(x_test)\n",
    "        test_pred = np.array([item for sublist in test_pred for item in sublist])\n",
    "\n",
    "        print(\"-------- Model : NN ---------\")\n",
    "\n",
    "        train_best_pred, train_best_pred_hold, hold_best_pred_train, hold_best_pred,test_best_pred, test_best_pred_hold = self.get_scores(train_pred, y_train, hold_pred, y_hold, test_pred)\n",
    "\n",
    "        return_dict = {\n",
    "            \"train_pred\": train_pred,\n",
    "            \"hold_pred\" : hold_pred,\n",
    "            \"test_pred\" : test_pred,\n",
    "            \"train_best_pred\" : train_best_pred,\n",
    "            \"train_best_pred_hold\" : train_best_pred_hold,\n",
    "            \"hold_best_pred_train\" : hold_best_pred_train,\n",
    "            \"hold_best_pred\" : hold_best_pred,\n",
    "            \"test_best_pred\" : test_best_pred,\n",
    "            \"test_best_pred_hold\": test_best_pred_hold\n",
    "        }\n",
    "\n",
    "        return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\tvalid_0's rmse: 1.16574\tvalid_0's l2: 1.35894\n",
      "[200]\tvalid_0's rmse: 1.10749\tvalid_0's l2: 1.22653\n",
      "[300]\tvalid_0's rmse: 1.07896\tvalid_0's l2: 1.16416\n",
      "[400]\tvalid_0's rmse: 1.06352\tvalid_0's l2: 1.13108\n",
      "[500]\tvalid_0's rmse: 1.05518\tvalid_0's l2: 1.1134\n",
      "[600]\tvalid_0's rmse: 1.05027\tvalid_0's l2: 1.10306\n",
      "[700]\tvalid_0's rmse: 1.04736\tvalid_0's l2: 1.09697\n",
      "[800]\tvalid_0's rmse: 1.04542\tvalid_0's l2: 1.09291\n",
      "[900]\tvalid_0's rmse: 1.04424\tvalid_0's l2: 1.09045\n",
      "[1000]\tvalid_0's rmse: 1.0436\tvalid_0's l2: 1.08911\n",
      "[1100]\tvalid_0's rmse: 1.04304\tvalid_0's l2: 1.08794\n",
      "[1200]\tvalid_0's rmse: 1.04236\tvalid_0's l2: 1.0865\n",
      "[1300]\tvalid_0's rmse: 1.04209\tvalid_0's l2: 1.08596\n",
      "[1400]\tvalid_0's rmse: 1.04215\tvalid_0's l2: 1.08608\n",
      "[1500]\tvalid_0's rmse: 1.04207\tvalid_0's l2: 1.08591\n",
      "Early stopping, best iteration is:\n",
      "[1259]\tvalid_0's rmse: 1.04198\tvalid_0's l2: 1.08572\n",
      "-------- Model : LGB ---------\n",
      "\n",
      "\n",
      "** Train RMSE :  0.8395346047175742\n",
      "** Hold  RMSE :  1.085715863158928\n",
      "\n",
      "\n",
      "Train Best_Score :  0.6677922891910425\n",
      "Train Best_Coef :  [1.0, 1.7, 2.2]\n",
      "\n",
      "\n",
      "Optmized Coefficients :  [1.04714359 1.69278671 2.22738142]\n",
      "Optimized Train qwk :  0.6689666282752169\n",
      "Hold Best_Score :  0.5707569846680067\n",
      "Hold Best_Coef :  [1.0, 1.7, 2.2]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hold QWK Train_Coef :  0.5592914786269978\n",
      "0:\tlearn: 1.2492253\ttest: 1.2817424\tbest: 1.2817424 (0)\ttotal: 1.29s\tremaining: 1h 47m 52s\n",
      "100:\tlearn: 0.9729862\ttest: 1.0685744\tbest: 1.0685744 (100)\ttotal: 1m 59s\tremaining: 1h 36m 30s\n",
      "200:\tlearn: 0.9168466\ttest: 1.0510158\tbest: 1.0510158 (200)\ttotal: 3m 58s\tremaining: 1h 34m 48s\n",
      "300:\tlearn: 0.8862843\ttest: 1.0463279\tbest: 1.0463279 (300)\ttotal: 5m 57s\tremaining: 1h 32m 55s\n",
      "400:\tlearn: 0.8635415\ttest: 1.0437222\tbest: 1.0435766 (386)\ttotal: 7m 57s\tremaining: 1h 31m 17s\n",
      "500:\tlearn: 0.8429494\ttest: 1.0419904\tbest: 1.0418118 (494)\ttotal: 9m 55s\tremaining: 1h 29m 6s\n",
      "600:\tlearn: 0.8193670\ttest: 1.0412867\tbest: 1.0410073 (592)\ttotal: 11m 54s\tremaining: 1h 27m 6s\n",
      "700:\tlearn: 0.7973222\ttest: 1.0406197\tbest: 1.0406197 (700)\ttotal: 13m 52s\tremaining: 1h 25m 2s\n",
      "800:\tlearn: 0.7758159\ttest: 1.0399011\tbest: 1.0399011 (800)\ttotal: 15m 49s\tremaining: 1h 22m 58s\n",
      "900:\tlearn: 0.7579579\ttest: 1.0400572\tbest: 1.0397033 (842)\ttotal: 17m 48s\tremaining: 1h 21m\n",
      "1000:\tlearn: 0.7407417\ttest: 1.0394749\tbest: 1.0394749 (1000)\ttotal: 19m 48s\tremaining: 1h 19m 9s\n",
      "1100:\tlearn: 0.7252155\ttest: 1.0405770\tbest: 1.0394546 (1001)\ttotal: 21m 46s\tremaining: 1h 17m 8s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 1.039454642\n",
      "bestIteration = 1001\n",
      "\n",
      "Shrink model to first 1002 iterations.\n",
      "-------- Model : CatBoost ---------\n",
      "\n",
      "\n",
      "** Train RMSE :  0.5484342717529443\n",
      "** Hold  RMSE :  1.080465953642526\n",
      "\n",
      "\n",
      "Train Best_Score :  0.8150682726036789\n",
      "Train Best_Coef :  [1.1, 1.7, 2.2]\n",
      "\n",
      "\n",
      "Optmized Coefficients :  [1.1311506  1.70185681 2.186708  ]\n",
      "Optimized Train qwk :  0.8158926854985853\n",
      "Hold Best_Score :  0.5758410917807879\n",
      "Hold Best_Coef :  [1.3, 1.6, 2.1]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hold QWK Train_Coef :  0.5658157340523944\n",
      "[0]\ttrain-rmse:1.85101\thold-rmse:1.84675\n",
      "Multiple eval metrics have been passed: 'hold-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until hold-rmse hasn't improved in 300 rounds.\n",
      "[100]\ttrain-rmse:0.983938\thold-rmse:1.19091\n",
      "[200]\ttrain-rmse:0.687179\thold-rmse:1.06949\n",
      "[300]\ttrain-rmse:0.573476\thold-rmse:1.05312\n",
      "[400]\ttrain-rmse:0.512935\thold-rmse:1.05052\n",
      "[500]\ttrain-rmse:0.474753\thold-rmse:1.05109\n",
      "[600]\ttrain-rmse:0.448682\thold-rmse:1.05166\n",
      "[700]\ttrain-rmse:0.425713\thold-rmse:1.05173\n",
      "Stopping. Best iteration:\n",
      "[447]\ttrain-rmse:0.493613\thold-rmse:1.04987\n",
      "\n",
      "-------- Model : XGB ---------\n",
      "\n",
      "\n",
      "** Train RMSE :  0.1721495326142595\n",
      "** Hold  RMSE :  1.1071860035353847\n",
      "\n",
      "\n",
      "Train Best_Score :  0.9576760873648972\n",
      "Train Best_Coef :  [0.8, 1.8, 2.3]\n",
      "\n",
      "\n",
      "Optmized Coefficients :  [0.82484231 1.7899267  2.31764781]\n",
      "Optimized Train qwk :  0.958244363225077\n",
      "Hold Best_Score :  0.5575468021071496\n",
      "Hold Best_Coef :  [1.0, 1.5, 2.2]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hold QWK Train_Coef :  0.5333950535643434\n"
     ]
    }
   ],
   "source": [
    "# tree based\n",
    "base = Base_Model(final_train_tree, hold_out_tree, reduce_test_tree, col_drop)\n",
    "x_train, y_train, x_hold, y_hold, x_test = base.get_tree_based_data()\n",
    "\n",
    "LGBTree = base.Lgb_Model(x_train, y_train, x_hold,y_hold ,x_test)\n",
    "CatTree = base.Catb_Model(x_train, y_train, x_hold,y_hold ,x_test)\n",
    "XGBTree = base.Xgb_Model(x_train, y_train, x_hold,y_hold ,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\tvalid_0's rmse: 1.16871\tvalid_0's l2: 1.36587\n",
      "[200]\tvalid_0's rmse: 1.11296\tvalid_0's l2: 1.23868\n",
      "[300]\tvalid_0's rmse: 1.08603\tvalid_0's l2: 1.17946\n",
      "[400]\tvalid_0's rmse: 1.07059\tvalid_0's l2: 1.14615\n",
      "[500]\tvalid_0's rmse: 1.0606\tvalid_0's l2: 1.12487\n",
      "[600]\tvalid_0's rmse: 1.05463\tvalid_0's l2: 1.11225\n",
      "[700]\tvalid_0's rmse: 1.05137\tvalid_0's l2: 1.10538\n",
      "[800]\tvalid_0's rmse: 1.0495\tvalid_0's l2: 1.10145\n",
      "[900]\tvalid_0's rmse: 1.04817\tvalid_0's l2: 1.09867\n",
      "[1000]\tvalid_0's rmse: 1.04697\tvalid_0's l2: 1.09614\n",
      "[1100]\tvalid_0's rmse: 1.04552\tvalid_0's l2: 1.0931\n",
      "[1200]\tvalid_0's rmse: 1.04476\tvalid_0's l2: 1.09152\n",
      "[1300]\tvalid_0's rmse: 1.04467\tvalid_0's l2: 1.09134\n",
      "[1400]\tvalid_0's rmse: 1.04453\tvalid_0's l2: 1.09105\n",
      "[1500]\tvalid_0's rmse: 1.04426\tvalid_0's l2: 1.09048\n",
      "[1600]\tvalid_0's rmse: 1.04418\tvalid_0's l2: 1.09031\n",
      "[1700]\tvalid_0's rmse: 1.04401\tvalid_0's l2: 1.08995\n",
      "[1800]\tvalid_0's rmse: 1.04386\tvalid_0's l2: 1.08965\n",
      "[1900]\tvalid_0's rmse: 1.04371\tvalid_0's l2: 1.08934\n",
      "[2000]\tvalid_0's rmse: 1.04364\tvalid_0's l2: 1.08918\n",
      "[2100]\tvalid_0's rmse: 1.0436\tvalid_0's l2: 1.08911\n",
      "[2200]\tvalid_0's rmse: 1.0435\tvalid_0's l2: 1.08888\n",
      "[2300]\tvalid_0's rmse: 1.04321\tvalid_0's l2: 1.08829\n",
      "[2400]\tvalid_0's rmse: 1.0432\tvalid_0's l2: 1.08828\n",
      "[2500]\tvalid_0's rmse: 1.04293\tvalid_0's l2: 1.08771\n",
      "[2600]\tvalid_0's rmse: 1.04298\tvalid_0's l2: 1.08781\n",
      "[2700]\tvalid_0's rmse: 1.04305\tvalid_0's l2: 1.08795\n",
      "[2800]\tvalid_0's rmse: 1.04287\tvalid_0's l2: 1.08757\n",
      "[2900]\tvalid_0's rmse: 1.04272\tvalid_0's l2: 1.08727\n",
      "[3000]\tvalid_0's rmse: 1.04266\tvalid_0's l2: 1.08714\n",
      "[3100]\tvalid_0's rmse: 1.04267\tvalid_0's l2: 1.08715\n",
      "[3200]\tvalid_0's rmse: 1.0427\tvalid_0's l2: 1.08721\n",
      "[3300]\tvalid_0's rmse: 1.04252\tvalid_0's l2: 1.08684\n",
      "[3400]\tvalid_0's rmse: 1.04249\tvalid_0's l2: 1.08678\n",
      "[3500]\tvalid_0's rmse: 1.0424\tvalid_0's l2: 1.0866\n",
      "[3600]\tvalid_0's rmse: 1.04238\tvalid_0's l2: 1.08656\n",
      "[3700]\tvalid_0's rmse: 1.04219\tvalid_0's l2: 1.08617\n",
      "[3800]\tvalid_0's rmse: 1.0421\tvalid_0's l2: 1.08598\n",
      "[3900]\tvalid_0's rmse: 1.04214\tvalid_0's l2: 1.08606\n",
      "[4000]\tvalid_0's rmse: 1.04217\tvalid_0's l2: 1.08612\n",
      "[4100]\tvalid_0's rmse: 1.04208\tvalid_0's l2: 1.08594\n",
      "Early stopping, best iteration is:\n",
      "[3812]\tvalid_0's rmse: 1.04203\tvalid_0's l2: 1.08583\n",
      "-------- Model : LGB ---------\n",
      "\n",
      "\n",
      "** Train RMSE :  0.6778427632495567\n",
      "** Hold  RMSE :  1.0858323899535083\n",
      "\n",
      "\n",
      "Train Best_Score :  0.74436669516865\n",
      "Train Best_Coef :  [1.0, 1.8, 2.2]\n",
      "\n",
      "\n",
      "Optmized Coefficients :  [1.01745632 1.80352772 2.22885941]\n",
      "Optimized Train qwk :  0.7451966375671257\n",
      "Hold Best_Score :  0.5694103368899192\n",
      "Hold Best_Coef :  [1.0, 1.6, 2.1]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hold QWK Train_Coef :  0.5570697800637998\n",
      "0:\tlearn: 1.2479529\ttest: 1.2811499\tbest: 1.2811499 (0)\ttotal: 1.3s\tremaining: 1h 48m 7s\n",
      "100:\tlearn: 0.9634426\ttest: 1.0686275\tbest: 1.0686275 (100)\ttotal: 2m 1s\tremaining: 1h 38m 14s\n",
      "200:\tlearn: 0.9110327\ttest: 1.0516010\tbest: 1.0516010 (200)\ttotal: 4m 1s\tremaining: 1h 35m 56s\n",
      "300:\tlearn: 0.8808760\ttest: 1.0469873\tbest: 1.0469873 (300)\ttotal: 6m\tremaining: 1h 33m 42s\n",
      "400:\tlearn: 0.8591185\ttest: 1.0451281\tbest: 1.0450834 (394)\ttotal: 8m 1s\tremaining: 1h 31m 59s\n",
      "500:\tlearn: 0.8384206\ttest: 1.0430401\tbest: 1.0430183 (486)\ttotal: 10m 1s\tremaining: 1h 30m 3s\n",
      "600:\tlearn: 0.8178904\ttest: 1.0405520\tbest: 1.0405474 (599)\ttotal: 12m 1s\tremaining: 1h 27m 59s\n",
      "700:\tlearn: 0.7963598\ttest: 1.0391430\tbest: 1.0390229 (694)\ttotal: 14m 2s\tremaining: 1h 26m 5s\n",
      "800:\tlearn: 0.7797039\ttest: 1.0393030\tbest: 1.0390229 (694)\ttotal: 16m 1s\tremaining: 1h 23m 58s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 1.039022887\n",
      "bestIteration = 694\n",
      "\n",
      "Shrink model to first 695 iterations.\n",
      "-------- Model : CatBoost ---------\n",
      "\n",
      "\n",
      "** Train RMSE :  0.6359676111653426\n",
      "** Hold  RMSE :  1.079568558701817\n",
      "\n",
      "\n",
      "Train Best_Score :  0.7703120845389676\n",
      "Train Best_Coef :  [1.1, 1.8, 2.2]\n",
      "\n",
      "\n",
      "Optmized Coefficients :  [1.11991362 1.79243039 2.18996584]\n",
      "Optimized Train qwk :  0.7707372656142611\n",
      "Hold Best_Score :  0.5732770167096495\n",
      "Hold Best_Coef :  [1.2, 1.6, 2.1]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hold QWK Train_Coef :  0.552733818310886\n",
      "[0]\ttrain-rmse:1.85084\thold-rmse:1.8467\n",
      "Multiple eval metrics have been passed: 'hold-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until hold-rmse hasn't improved in 300 rounds.\n",
      "[100]\ttrain-rmse:0.970528\thold-rmse:1.1869\n",
      "[200]\ttrain-rmse:0.678336\thold-rmse:1.06446\n",
      "[300]\ttrain-rmse:0.564195\thold-rmse:1.04783\n",
      "[400]\ttrain-rmse:0.506995\thold-rmse:1.04647\n",
      "[500]\ttrain-rmse:0.471674\thold-rmse:1.04696\n",
      "[600]\ttrain-rmse:0.444726\thold-rmse:1.04801\n",
      "[700]\ttrain-rmse:0.422423\thold-rmse:1.04848\n",
      "Stopping. Best iteration:\n",
      "[441]\ttrain-rmse:0.493264\thold-rmse:1.04618\n",
      "\n",
      "-------- Model : XGB ---------\n",
      "\n",
      "\n",
      "** Train RMSE :  0.17115247290298485\n",
      "** Hold  RMSE :  1.0998786931249338\n",
      "\n",
      "\n",
      "Train Best_Score :  0.9563222555566409\n",
      "Train Best_Coef :  [0.8, 1.8, 2.3]\n",
      "\n",
      "\n",
      "Optmized Coefficients :  [0.84220639 1.77834641 2.35027383]\n",
      "Optimized Train qwk :  0.9571100131476515\n",
      "Hold Best_Score :  0.563786148611194\n",
      "Hold Best_Coef :  [1.0, 1.9, 2.2]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hold QWK Train_Coef :  0.5426441496889371\n",
      "-------- Model : Lasso ---------\n",
      "\n",
      "\n",
      "** Train RMSE :  1.0061259152681747\n",
      "** Hold  RMSE :  1.1390297170001924\n",
      "\n",
      "\n",
      "Train Best_Score :  0.590327257271843\n",
      "Train Best_Coef :  [1.2, 1.5, 2.2]\n",
      "\n",
      "\n",
      "Optmized Coefficients :  [1.1957844  1.56956564 2.12302231]\n",
      "Optimized Train qwk :  0.5925185167096996\n",
      "Hold Best_Score :  0.5589683453086552\n",
      "Hold Best_Coef :  [1.1, 1.5, 2.1]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hold QWK Train_Coef :  0.5411563033508715\n",
      "-------- Model : ElasticNet ---------\n",
      "\n",
      "\n",
      "** Train RMSE :  1.0012429980970738\n",
      "** Hold  RMSE :  1.136624009511084\n",
      "\n",
      "\n",
      "Train Best_Score :  0.5935788920498958\n",
      "Train Best_Coef :  [1.2, 1.5, 2.1]\n",
      "\n",
      "\n",
      "Optmized Coefficients :  [1.22836806 1.48864294 2.11375289]\n",
      "Optimized Train qwk :  0.5951416771513746\n",
      "Hold Best_Score :  0.5552203390102071\n",
      "Hold Best_Coef :  [1.1, 1.5, 2.1]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hold QWK Train_Coef :  0.548114381591785\n",
      "-------- Model : BayesianRidge ---------\n",
      "\n",
      "\n",
      "** Train RMSE :  0.9439206772618848\n",
      "** Hold  RMSE :  1.1202974355286262\n",
      "\n",
      "\n",
      "Train Best_Score :  0.6226368603251576\n",
      "Train Best_Coef :  [1.1, 1.5, 2.1]\n",
      "\n",
      "\n",
      "Optmized Coefficients :  [1.14388119 1.55531567 2.10733032]\n",
      "Optimized Train qwk :  0.6274801792529552\n",
      "Hold Best_Score :  0.5605862166149969\n",
      "Hold Best_Coef :  [1.4, 1.5, 2.1]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hold QWK Train_Coef :  0.5554414348321332\n",
      "-------- Model : HuberRegressor ---------\n",
      "\n",
      "\n",
      "** Train RMSE :  0.9616706799581555\n",
      "** Hold  RMSE :  1.174913102483116\n",
      "\n",
      "\n",
      "Train Best_Score :  0.6212408099671831\n",
      "Train Best_Coef :  [1.0, 1.6, 2.3]\n",
      "\n",
      "\n",
      "Optmized Coefficients :  [1.02447882 1.60782575 2.31954687]\n",
      "Optimized Train qwk :  0.6223836163747145\n",
      "Hold Best_Score :  0.5456440408259196\n",
      "Hold Best_Coef :  [1.1, 1.5, 2.4]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hold QWK Train_Coef :  0.5384435185901253\n",
      "Train on 14743 samples, validate on 930 samples\n",
      "Epoch 1/100\n",
      "14743/14743 [==============================] - 11s 761us/step - loss: 2.6529 - val_loss: 1.7166\n",
      "Epoch 2/100\n",
      "14743/14743 [==============================] - 9s 630us/step - loss: 1.5240 - val_loss: 1.3353\n",
      "Epoch 3/100\n",
      "14743/14743 [==============================] - 9s 627us/step - loss: 1.1964 - val_loss: 1.3051\n",
      "Epoch 4/100\n",
      "14743/14743 [==============================] - 9s 590us/step - loss: 1.1223 - val_loss: 1.3694\n",
      "Epoch 5/100\n",
      "14743/14743 [==============================] - 9s 595us/step - loss: 1.1084 - val_loss: 1.2155\n",
      "Epoch 6/100\n",
      "14743/14743 [==============================] - 9s 597us/step - loss: 1.0721 - val_loss: 1.1624\n",
      "Epoch 7/100\n",
      "14743/14743 [==============================] - 9s 591us/step - loss: 1.0472 - val_loss: 1.2135\n",
      "Epoch 8/100\n",
      "14743/14743 [==============================] - 9s 597us/step - loss: 1.0609 - val_loss: 1.2487\n",
      "Epoch 9/100\n",
      "14743/14743 [==============================] - 9s 615us/step - loss: 1.0358 - val_loss: 1.1266\n",
      "Epoch 10/100\n",
      "14743/14743 [==============================] - 9s 590us/step - loss: 1.0222 - val_loss: 1.1367\n",
      "Epoch 11/100\n",
      "14743/14743 [==============================] - 9s 592us/step - loss: 1.0189 - val_loss: 1.1528\n",
      "Epoch 12/100\n",
      "14743/14743 [==============================] - 9s 598us/step - loss: 1.0012 - val_loss: 1.1274\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 13/100\n",
      "14743/14743 [==============================] - 9s 617us/step - loss: 0.9807 - val_loss: 1.1380\n",
      "Epoch 14/100\n",
      "14743/14743 [==============================] - 9s 592us/step - loss: 0.9796 - val_loss: 1.1220\n",
      "Epoch 15/100\n",
      "14743/14743 [==============================] - 9s 607us/step - loss: 0.9696 - val_loss: 1.1060\n",
      "Epoch 16/100\n",
      "14743/14743 [==============================] - 9s 610us/step - loss: 0.9597 - val_loss: 1.1063\n",
      "Epoch 17/100\n",
      "14743/14743 [==============================] - 9s 612us/step - loss: 0.9708 - val_loss: 1.1615\n",
      "Epoch 18/100\n",
      "14743/14743 [==============================] - 9s 592us/step - loss: 0.9562 - val_loss: 1.1295\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 19/100\n",
      "14743/14743 [==============================] - 10s 663us/step - loss: 0.9317 - val_loss: 1.1150\n",
      "Epoch 20/100\n",
      "14743/14743 [==============================] - 9s 592us/step - loss: 0.9236 - val_loss: 1.1194\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00020: early stopping\n",
      "-------- Model : NN ---------\n",
      "\n",
      "\n",
      "** Train RMSE :  0.8939907457900006\n",
      "** Hold  RMSE :  1.1041191768314906\n",
      "\n",
      "\n",
      "Train Best_Score :  0.6417002289831246\n",
      "Train Best_Coef :  [1.0, 1.7, 2.3]\n",
      "\n",
      "\n",
      "Optmized Coefficients :  [1.03735711 1.63047673 2.28228469]\n",
      "Optimized Train qwk :  0.6427088235786825\n",
      "Hold Best_Score :  0.5646480909140535\n",
      "Hold Best_Coef :  [0.9, 1.7, 2.1]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hold QWK Train_Coef :  0.5554768911663293\n"
     ]
    }
   ],
   "source": [
    "# linear based\n",
    "base = Base_Model(final_train_linear, hold_out_linear, reduce_test_linear, col_drop)\n",
    "x_train, y_train, x_hold, y_hold, x_test = base.get_linear_based_data()\n",
    "\n",
    "LGBLinear = base.Lgb_Model(x_train, y_train, x_hold,y_hold ,x_test)\n",
    "CatLinear = base.Catb_Model(x_train, y_train, x_hold,y_hold ,x_test)\n",
    "XGBLinear = base.Xgb_Model(x_train, y_train, x_hold,y_hold ,x_test)\n",
    "\n",
    "Lasso_Model = base.Lasso_Model(x_train, y_train, x_hold,y_hold ,x_test)\n",
    "ElasticNet_Model = base.ElasticNet_Model(x_train, y_train, x_hold,y_hold ,x_test)\n",
    "BayesianRidge_Model = base.BayesianRidge_Model(x_train, y_train, x_hold,y_hold ,x_test)\n",
    "HuberRegressor_Model = base.HuberRegressor_Model(x_train, y_train, x_hold,y_hold ,x_test)\n",
    "NN_Model = base.NN_Model(x_train, y_train, x_hold, y_hold, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\tvalid_0's rmse: 1.16792\tvalid_0's l2: 1.36404\n",
      "[200]\tvalid_0's rmse: 1.11224\tvalid_0's l2: 1.23708\n",
      "[300]\tvalid_0's rmse: 1.08523\tvalid_0's l2: 1.17772\n",
      "[400]\tvalid_0's rmse: 1.06995\tvalid_0's l2: 1.14479\n",
      "[500]\tvalid_0's rmse: 1.05994\tvalid_0's l2: 1.12347\n",
      "[600]\tvalid_0's rmse: 1.05429\tvalid_0's l2: 1.11152\n",
      "[700]\tvalid_0's rmse: 1.0511\tvalid_0's l2: 1.10481\n",
      "[800]\tvalid_0's rmse: 1.04923\tvalid_0's l2: 1.10089\n",
      "[900]\tvalid_0's rmse: 1.04772\tvalid_0's l2: 1.09771\n",
      "[1000]\tvalid_0's rmse: 1.04632\tvalid_0's l2: 1.09479\n",
      "[1100]\tvalid_0's rmse: 1.04514\tvalid_0's l2: 1.09231\n",
      "[1200]\tvalid_0's rmse: 1.04429\tvalid_0's l2: 1.09054\n",
      "[1300]\tvalid_0's rmse: 1.04379\tvalid_0's l2: 1.0895\n",
      "[1400]\tvalid_0's rmse: 1.04356\tvalid_0's l2: 1.08901\n",
      "[1500]\tvalid_0's rmse: 1.0433\tvalid_0's l2: 1.08848\n",
      "[1600]\tvalid_0's rmse: 1.04316\tvalid_0's l2: 1.08818\n",
      "[1700]\tvalid_0's rmse: 1.04319\tvalid_0's l2: 1.08825\n",
      "[1800]\tvalid_0's rmse: 1.04331\tvalid_0's l2: 1.0885\n",
      "[1900]\tvalid_0's rmse: 1.04332\tvalid_0's l2: 1.08852\n",
      "Early stopping, best iteration is:\n",
      "[1666]\tvalid_0's rmse: 1.04304\tvalid_0's l2: 1.08794\n",
      "-------- Model : LGB ---------\n",
      "\n",
      "\n",
      "** Train RMSE :  0.7993494968264337\n",
      "** Hold  RMSE :  1.0879368854001414\n",
      "\n",
      "\n",
      "Train Best_Score :  0.6858706698121859\n",
      "Train Best_Coef :  [1.1, 1.7, 2.2]\n",
      "\n",
      "\n",
      "Optmized Coefficients :  [1.10722018 1.6455596  2.20996293]\n",
      "Optimized Train qwk :  0.687060243685404\n",
      "Hold Best_Score :  0.5705217852439599\n",
      "Hold Best_Coef :  [1.0, 1.6, 2.1]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hold QWK Train_Coef :  0.5616140703470759\n",
      "0:\tlearn: 1.2481126\ttest: 1.2813330\tbest: 1.2813330 (0)\ttotal: 1.21s\tremaining: 1h 40m 46s\n",
      "100:\tlearn: 0.9634202\ttest: 1.0694832\tbest: 1.0694832 (100)\ttotal: 1m 54s\tremaining: 1h 32m 40s\n",
      "200:\tlearn: 0.9114947\ttest: 1.0545493\tbest: 1.0545297 (198)\ttotal: 3m 48s\tremaining: 1h 31m 1s\n",
      "300:\tlearn: 0.8793032\ttest: 1.0477138\tbest: 1.0475719 (295)\ttotal: 5m 42s\tremaining: 1h 29m 7s\n",
      "400:\tlearn: 0.8578573\ttest: 1.0456249\tbest: 1.0454411 (395)\ttotal: 7m 36s\tremaining: 1h 27m 14s\n",
      "500:\tlearn: 0.8363375\ttest: 1.0438555\tbest: 1.0437016 (493)\ttotal: 9m 30s\tremaining: 1h 25m 22s\n",
      "600:\tlearn: 0.8155733\ttest: 1.0438660\tbest: 1.0431876 (562)\ttotal: 11m 26s\tremaining: 1h 23m 47s\n",
      "700:\tlearn: 0.7957239\ttest: 1.0434487\tbest: 1.0431876 (562)\ttotal: 13m 20s\tremaining: 1h 21m 50s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 1.043187622\n",
      "bestIteration = 562\n",
      "\n",
      "Shrink model to first 563 iterations.\n",
      "-------- Model : CatBoost ---------\n",
      "\n",
      "\n",
      "** Train RMSE :  0.6768692042635496\n",
      "** Hold  RMSE :  1.0882404153912562\n",
      "\n",
      "\n",
      "Train Best_Score :  0.7487671708617245\n",
      "Train Best_Coef :  [1.2, 1.8, 2.2]\n",
      "\n",
      "\n",
      "Optmized Coefficients :  [1.15744663 1.77407199 2.19418889]\n",
      "Optimized Train qwk :  0.7507775974360076\n",
      "Hold Best_Score :  0.5751314737784521\n",
      "Hold Best_Coef :  [1.0, 1.7, 2.2]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hold QWK Train_Coef :  0.5614707319162532\n",
      "[0]\ttrain-rmse:1.85092\thold-rmse:1.84672\n",
      "Multiple eval metrics have been passed: 'hold-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until hold-rmse hasn't improved in 300 rounds.\n",
      "[100]\ttrain-rmse:0.970266\thold-rmse:1.18355\n",
      "[200]\ttrain-rmse:0.680646\thold-rmse:1.05943\n",
      "[300]\ttrain-rmse:0.568097\thold-rmse:1.04343\n",
      "[400]\ttrain-rmse:0.507185\thold-rmse:1.04264\n",
      "[500]\ttrain-rmse:0.471787\thold-rmse:1.04193\n",
      "[600]\ttrain-rmse:0.446349\thold-rmse:1.04167\n",
      "[700]\ttrain-rmse:0.425714\thold-rmse:1.04314\n",
      "[800]\ttrain-rmse:0.404998\thold-rmse:1.04324\n",
      "Stopping. Best iteration:\n",
      "[562]\ttrain-rmse:0.455842\thold-rmse:1.04141\n",
      "\n",
      "-------- Model : XGB ---------\n",
      "\n",
      "\n",
      "** Train RMSE :  0.1548581566131887\n",
      "** Hold  RMSE :  1.0885745871303538\n",
      "\n",
      "\n",
      "Train Best_Score :  0.9611560801393586\n",
      "Train Best_Coef :  [0.8, 1.8, 2.3]\n",
      "\n",
      "\n",
      "Optmized Coefficients :  [0.8079384  1.80177957 2.32647557]\n",
      "Optimized Train qwk :  0.9622691848359778\n",
      "Hold Best_Score :  0.5730981181912812\n",
      "Hold Best_Coef :  [1.1, 1.7, 2.2]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hold QWK Train_Coef :  0.544983958052871\n",
      "-------- Model : Lasso ---------\n",
      "\n",
      "\n",
      "** Train RMSE :  1.0061757782845395\n",
      "** Hold  RMSE :  1.139284171174538\n",
      "\n",
      "\n",
      "Train Best_Score :  0.5906384954773689\n",
      "Train Best_Coef :  [1.2, 1.6, 2.2]\n",
      "\n",
      "\n",
      "Optmized Coefficients :  [1.23416492 1.5715068  2.18546213]\n",
      "Optimized Train qwk :  0.5920581941970433\n",
      "Hold Best_Score :  0.5599812842097621\n",
      "Hold Best_Coef :  [1.1, 1.5, 2.1]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hold QWK Train_Coef :  0.5328507484826674\n",
      "-------- Model : ElasticNet ---------\n",
      "\n",
      "\n",
      "** Train RMSE :  1.0012770493418695\n",
      "** Hold  RMSE :  1.1369621629632438\n",
      "\n",
      "\n",
      "Train Best_Score :  0.593355376682263\n",
      "Train Best_Coef :  [1.2, 1.5, 2.1]\n",
      "\n",
      "\n",
      "Optmized Coefficients :  [1.21267216 1.52816943 2.11750135]\n",
      "Optimized Train qwk :  0.5952357892714424\n",
      "Hold Best_Score :  0.5568859640349648\n",
      "Hold Best_Coef :  [1.1, 1.5, 2.1]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hold QWK Train_Coef :  0.5490902106151001\n",
      "-------- Model : BayesianRidge ---------\n",
      "\n",
      "\n",
      "** Train RMSE :  0.9446107955574479\n",
      "** Hold  RMSE :  1.1201356824392978\n",
      "\n",
      "\n",
      "Train Best_Score :  0.6236674153091919\n",
      "Train Best_Coef :  [1.1, 1.5, 2.1]\n",
      "\n",
      "\n",
      "Optmized Coefficients :  [1.13157745 1.538617   2.10102476]\n",
      "Optimized Train qwk :  0.6266970350696834\n",
      "Hold Best_Score :  0.5606915469330843\n",
      "Hold Best_Coef :  [1.1, 1.6, 2.2]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hold QWK Train_Coef :  0.5596982653584588\n",
      "-------- Model : HuberRegressor ---------\n",
      "\n",
      "\n",
      "** Train RMSE :  0.9634252334368361\n",
      "** Hold  RMSE :  1.1765775679258401\n",
      "\n",
      "\n",
      "Train Best_Score :  0.6210952690464926\n",
      "Train Best_Coef :  [1.0, 1.7, 2.4]\n",
      "\n",
      "\n",
      "Optmized Coefficients :  [0.99917543 1.70152467 2.39847242]\n",
      "Optimized Train qwk :  0.6215071772359185\n",
      "Hold Best_Score :  0.5426847639700494\n",
      "Hold Best_Coef :  [1.1, 1.6, 2.3]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hold QWK Train_Coef :  0.5320207467570689\n",
      "Train on 14743 samples, validate on 930 samples\n",
      "Epoch 1/100\n",
      "14743/14743 [==============================] - 11s 742us/step - loss: 2.7819 - val_loss: 1.8588\n",
      "Epoch 2/100\n",
      "14743/14743 [==============================] - 8s 576us/step - loss: 1.4458 - val_loss: 1.3664\n",
      "Epoch 3/100\n",
      "14743/14743 [==============================] - 9s 583us/step - loss: 1.1768 - val_loss: 1.2090\n",
      "Epoch 4/100\n",
      "14743/14743 [==============================] - 9s 592us/step - loss: 1.1002 - val_loss: 1.1643\n",
      "Epoch 5/100\n",
      "14743/14743 [==============================] - 9s 587us/step - loss: 1.0634 - val_loss: 1.1602\n",
      "Epoch 6/100\n",
      "14743/14743 [==============================] - 9s 577us/step - loss: 1.0511 - val_loss: 1.1658\n",
      "Epoch 7/100\n",
      "14743/14743 [==============================] - 9s 589us/step - loss: 1.0354 - val_loss: 1.2270\n",
      "Epoch 8/100\n",
      "14743/14743 [==============================] - 9s 586us/step - loss: 1.0277 - val_loss: 1.1694\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 9/100\n",
      "14743/14743 [==============================] - 9s 585us/step - loss: 0.9892 - val_loss: 1.1128\n",
      "Epoch 10/100\n",
      "14743/14743 [==============================] - 8s 574us/step - loss: 0.9917 - val_loss: 1.1326\n",
      "Epoch 11/100\n",
      "14743/14743 [==============================] - 9s 588us/step - loss: 0.9786 - val_loss: 1.2016\n",
      "Epoch 12/100\n",
      "14743/14743 [==============================] - 9s 596us/step - loss: 0.9789 - val_loss: 1.1606\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 13/100\n",
      "14743/14743 [==============================] - 8s 570us/step - loss: 0.9579 - val_loss: 1.1181\n",
      "Epoch 14/100\n",
      "14743/14743 [==============================] - 8s 576us/step - loss: 0.9509 - val_loss: 1.1193\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "-------- Model : NN ---------\n",
      "\n",
      "\n",
      "** Train RMSE :  0.9264311644302902\n",
      "** Hold  RMSE :  1.110818290436461\n",
      "\n",
      "\n",
      "Train Best_Score :  0.6253570411299061\n",
      "Train Best_Coef :  [1.0, 1.6, 2.2]\n",
      "\n",
      "\n",
      "Optmized Coefficients :  [0.99642531 1.6235419  2.24164939]\n",
      "Optimized Train qwk :  0.6276125154105464\n",
      "Hold Best_Score :  0.56020403693808\n",
      "Hold Best_Coef :  [1.2, 1.8, 2.2]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hold QWK Train_Coef :  0.5509920683285932\n"
     ]
    }
   ],
   "source": [
    "# linear based\n",
    "useless_cols = list(correlation_to_drop)\n",
    "useless_cols.extend(list(col_drop))\n",
    "base = Base_Model(final_train_linear, hold_out_linear, reduce_test_linear, useless_cols)\n",
    "x_train, y_train, x_hold, y_hold, x_test = base.get_linear_based_data()\n",
    "\n",
    "LGBLinear_useless = base.Lgb_Model(x_train, y_train, x_hold,y_hold ,x_test)\n",
    "CatLinear_useless = base.Catb_Model(x_train, y_train, x_hold,y_hold ,x_test)\n",
    "XGBLinear_useless = base.Xgb_Model(x_train, y_train, x_hold,y_hold ,x_test)\n",
    "\n",
    "Lasso_Model_useless = base.Lasso_Model(x_train, y_train, x_hold,y_hold ,x_test)\n",
    "ElasticNet_Model_useless = base.ElasticNet_Model(x_train, y_train, x_hold,y_hold ,x_test)\n",
    "BayesianRidge_Model_useless = base.BayesianRidge_Model(x_train, y_train, x_hold,y_hold ,x_test)\n",
    "HuberRegressor_Model_useless = base.HuberRegressor_Model(x_train, y_train, x_hold,y_hold ,x_test)\n",
    "NN_Model_useless = base.NN_Model(x_train, y_train, x_hold, y_hold, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list_predicted = [[\"LGBTree_\", LGBTree],\n",
    "                         [\"CatTree_\", CatTree],\n",
    "                         [\"XGBTree_\", XGBTree],\n",
    "                         [\"LGBLinear_\", LGBLinear],\n",
    "                         [\"CatLinear_\", CatLinear],\n",
    "                         [\"XGBLinear_\", XGBLinear],\n",
    "                         [\"LassoLinear_\", Lasso_Model], \n",
    "                         [\"ElasticNetLinear_\", ElasticNet_Model], \n",
    "                         [\"BayesianRidgeLinear_\", BayesianRidge_Model],\n",
    "                         [\"HuberRegressorLinear_\", HuberRegressor_Model],\n",
    "                         [\"NNLinear_\", NN_Model],\n",
    "                         \n",
    "                         [\"LGBLinearUseless_\", LGBLinear_useless],\n",
    "                         [\"CatLinearUseless_\", CatLinear_useless],\n",
    "                         [\"XGBLinearUseless_\", XGBLinear_useless],\n",
    "                         [\"LassoLinearUseless_\", Lasso_Model_useless], \n",
    "                         [\"ElasticNetLinearUseless_\", ElasticNet_Model_useless], \n",
    "                         [\"BayesianRidgeLinearUseless_\", BayesianRidge_Model_useless],\n",
    "                         [\"HuberRegressorLinearUseless_\", HuberRegressor_Model_useless],\n",
    "                         [\"NNLinearUseless_\", NN_Model_useless]\n",
    "                         \n",
    "                        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_df2 = pd.DataFrame()\n",
    "train_df2 = pd.DataFrame()\n",
    "test_df2 = pd.DataFrame()\n",
    "for model_name, i in models_list_predicted:\n",
    "    for j in ['train_pred', 'hold_pred', 'test_pred', 'train_best_pred', 'train_best_pred_hold', 'hold_best_pred_train', 'hold_best_pred', 'test_best_pred', 'test_best_pred_hold']:\n",
    "        \n",
    "        if j.startswith(\"train\"):\n",
    "            train_df2[model_name+j] = i[j]\n",
    "        if j.startswith(\"hold\"):\n",
    "            hold_df2[model_name+j] = i[j]\n",
    "        if j.startswith(\"test\"):\n",
    "            test_df2[model_name+j] = i[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14743, 57), (930, 57), (1000, 57))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df2.shape, hold_df2.shape, test_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hold_2 = y_hold.values\n",
    "y_train_2 = y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14743, 57), (930, 57), (1000, 57))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df2.shape, hold_df2.shape, test_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mode = train_df2.mode(axis=1)\n",
    "train_mean = train_mode.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6729659772597081"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwk(round(train_mean), y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_mode = hold_df2.mode(axis=1)\n",
    "hold_mean = hold_mode.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5742437313738196"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwk(round(hold_mean), y_hold_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mode = test_df2.mode(axis=1)\n",
    "test_mean = test_mode.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicted = round(test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    0.443\n",
       "2.0    0.296\n",
       "0.0    0.149\n",
       "1.0    0.112\n",
       "dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predicted.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"/kaggle/input/data-science-bowl-2019/sample_submission.csv\")\n",
    "sample_submission[\"accuracy_group\"] = test_predicted.astype(\"int\")\n",
    "sample_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    0.443\n",
       "2    0.296\n",
       "0    0.149\n",
       "1    0.112\n",
       "Name: accuracy_group, dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission['accuracy_group'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2089d6aff648468099f13be80fb99923": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_498d1da5449a4239a538d1bcf161927c",
       "max": 1000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6ee91ee79e8f4285a77ae2e14d61efd7",
       "value": 1000
      }
     },
     "406ffbe8491147fdb0a02cb9b8ea042d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "498d1da5449a4239a538d1bcf161927c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4f1fc3cf7cea475aa14e0e577931d35d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "65c0b589be9e4b2691e6b7c018e277d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2089d6aff648468099f13be80fb99923",
        "IPY_MODEL_669535ce2d8b43bebb97c279e0a9b434"
       ],
       "layout": "IPY_MODEL_4f1fc3cf7cea475aa14e0e577931d35d"
      }
     },
     "669535ce2d8b43bebb97c279e0a9b434": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c79467b489484443bfdfdc6495651865",
       "placeholder": "​",
       "style": "IPY_MODEL_406ffbe8491147fdb0a02cb9b8ea042d",
       "value": " 1000/1000 [11:56&lt;00:00,  1.40it/s]"
      }
     },
     "6ee91ee79e8f4285a77ae2e14d61efd7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "c79467b489484443bfdfdc6495651865": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
